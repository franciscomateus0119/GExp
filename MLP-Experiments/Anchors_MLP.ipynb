{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ce9789-8b06-4305-b428-acdc15b0121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import docplex\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utility\n",
    "import copy\n",
    "import mlp_explainer\n",
    "import mymetrics\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from milp import codify_network\n",
    "from teste import get_minimal_explanation\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b33ced3-bd3b-40f0-8635-991db7df141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(50)\n",
    "def load_data(dataset_name):\n",
    "    if dataset_name == 'Iris':\n",
    "        dataset = datasets.load_iris()\n",
    "        df = pd.DataFrame(dataset.data, columns = dataset.feature_names)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(dataset.data)\n",
    "        scaled_df = scaler.transform(dataset.data)\n",
    "        df_scaled = pd.DataFrame(scaled_df, columns=df.columns)\n",
    "        targets = dataset.target\n",
    "        df_scaled['target'] = targets\n",
    "        columns = df_scaled.columns\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "        return X_train, X_test, y_train, y_test, columns, np.unique(targets)\n",
    "    elif dataset_name == 'Banknote':\n",
    "        df = pd.read_csv('./datasets/banknote_authentication.csv') \n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df.values[:, :-1])\n",
    "        scaled_df = scaler.transform(df.values[:, :-1])\n",
    "        df_scaled = pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "        #targets = (utility.check_targets_0_1(df.values[:,-1])).astype(np.int32)\n",
    "        targets = df['target'].values\n",
    "        df_scaled['target'] = targets\n",
    "        columns = df_scaled.columns\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "        return X_train, X_test, y_train, y_test, columns, np.unique(targets)\n",
    "    elif dataset_name == 'Blood_Transfusion':\n",
    "        df = pd.read_csv('./datasets/blood_transfusion.csv')\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df.values[:, :-1])\n",
    "        scaled_df = scaler.transform(df.values[:, :-1])\n",
    "        df_scaled = pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "        targets = (utility.check_targets_0_1(df.values[:,-1])).astype(np.int32)\n",
    "        df_scaled['target'] = targets\n",
    "        columns = df_scaled.columns\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "        return X_train, X_test, y_train, y_test, columns, np.unique(targets)\n",
    "    elif dataset_name == 'Breast_Cancer':\n",
    "        dataset = datasets.load_breast_cancer()\n",
    "        df = pd.DataFrame(dataset.data, columns = dataset.feature_names)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(dataset.data)\n",
    "        scaled_df = scaler.transform(dataset.data) \n",
    "        df_scaled = pd.DataFrame(scaled_df, columns=df.columns)\n",
    "        targets = (utility.check_targets_0_1(np.where(dataset.target == dataset.target[0],0,1))).astype(np.int32)\n",
    "        df_scaled['target'] = targets\n",
    "        columns = df_scaled.columns\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "        return X_train, X_test, y_train, y_test, columns, np.unique(targets)\n",
    "    elif dataset_name == 'Climate':\n",
    "        df = pd.read_csv('./datasets/climate_model_simulation_crashes.csv')\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df.values[:, :-1])\n",
    "        scaled_df = scaler.transform(df.values[:, :-1])\n",
    "        df_scaled = pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "        targets = df['target'].values\n",
    "        df_scaled['target'] = targets\n",
    "        columns = df_scaled.columns\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "        return X_train, X_test, y_train, y_test, columns, np.unique(targets)\n",
    "    elif dataset_name == 'Column':\n",
    "        df = pd.read_csv('./datasets/column_2C.dat', sep=\" \", names=['pelvic_incidence', 'pelvic_tilt', 'lumbar_lordosis_angle', 'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis','target'])\n",
    "        df['target']=np.where(df['target']=='AB',1,0)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df.values[:, :-1])\n",
    "        scaled_df = scaler.transform(df.values[:, :-1])\n",
    "        df_scaled = pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "        targets = (utility.check_targets_0_1(df.values[:,-1])).astype(np.int32)\n",
    "        df_scaled['target'] = targets\n",
    "        columns = df_scaled.columns\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "        return X_train, X_test, y_train, y_test, columns, np.unique(targets)\n",
    "    elif dataset_name == 'Glass':\n",
    "        df = pd.read_csv('./datasets/glass.csv')\n",
    "        unique_labels = sorted(df['target'].unique())\n",
    "        label_map = {original: new for new, original in enumerate(unique_labels)}\n",
    "        df['target'] = df['target'].map(label_map)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df.values[:, :-1])\n",
    "        scaled_df = scaler.transform(df.values[:, :-1])\n",
    "        df_scaled = pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "        targets = df['target'].values\n",
    "        df_scaled['target'] = targets\n",
    "        columns = df_scaled.columns\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "        return X_train, X_test, y_train, y_test, columns, np.unique(targets)\n",
    "    elif dataset_name == 'Ionosphere':\n",
    "        df = pd.read_csv('./datasets/Ionosphere.csv')\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df.values[:, :-1])\n",
    "        scaled_df = scaler.transform(df.values[:, :-1])\n",
    "        lower_bound = scaled_df.min()\n",
    "        upper_bound = scaled_df.max()\n",
    "        print(lower_bound, upper_bound)\n",
    "        df_scaled = pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "        targets = (utility.check_targets_0_1(df.values[:,-1])).astype(np.int32)\n",
    "        df_scaled['target'] = targets\n",
    "        columns = df_scaled.columns\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "        return X_train, X_test, y_train, y_test, columns, np.unique(targets)\n",
    "    elif dataset_name == 'Modeling':\n",
    "        df = pd.read_csv('./datasets/User_Knowledge_Modeling.csv')\n",
    "        unique_labels = sorted(df['target'].unique()) \n",
    "        label_map = {original: new for new, original in enumerate(unique_labels)}\n",
    "        df['target'] = df['target'].map(label_map)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df.values[:, :-1])\n",
    "        scaled_df = scaler.transform(df.values[:, :-1])\n",
    "        df_scaled = pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "        targets = df['target'].values\n",
    "        df_scaled['target'] = targets\n",
    "        columns = df_scaled.columns\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "        return X_train, X_test, y_train, y_test, columns, np.unique(targets)\n",
    "    elif dataset_name == 'Parkinson':\n",
    "        df = pd.read_csv('./datasets/parkinsons.csv')\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df.values[:, :-1])\n",
    "        scaled_df = scaler.transform(df.values[:, :-1])\n",
    "        lower_bound = scaled_df.min()\n",
    "        upper_bound = scaled_df.max()\n",
    "        print(lower_bound, upper_bound)\n",
    "        df_scaled = pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "        targets = (utility.check_targets_0_1(df.values[:,-1])).astype(np.int32)\n",
    "        df_scaled['target'] = targets\n",
    "        columns = df_scaled.columns\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "        return X_train, X_test, y_train, y_test, columns, np.unique(targets)\n",
    "    elif dataset_name == 'Pima':\n",
    "        df = pd.read_csv('./datasets/diabetes.csv')\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df.values[:, :-1])\n",
    "        scaled_df = scaler.transform(df.values[:, :-1])\n",
    "        df_scaled = pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "        targets = (utility.check_targets_0_1(df.values[:,-1])).astype(np.int32)\n",
    "        df_scaled['target'] = targets\n",
    "        columns = df_scaled.columns\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "        return X_train, X_test, y_train, y_test, columns, np.unique(targets)\n",
    "    elif dataset_name == 'Sonar':\n",
    "        df = pd.read_csv('./datasets/sonar.csv')\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df.values[:, :-1])\n",
    "        scaled_df = scaler.transform(df.values[:, :-1])\n",
    "        df_scaled = pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "        targets = df['target'].values\n",
    "        df_scaled['target'] = targets\n",
    "        columns = df_scaled.columns\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "        return X_train, X_test, y_train, y_test, columns, np.unique(targets)\n",
    "    elif dataset_name == 'Wine':\n",
    "        dataset = datasets.load_wine()\n",
    "        df = pd.DataFrame(dataset.data, columns = dataset.feature_names)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(dataset.data)\n",
    "        scaled_df = scaler.transform(dataset.data)\n",
    "        lower_bound = scaled_df.min()\n",
    "        upper_bound = scaled_df.max()\n",
    "        print(lower_bound, upper_bound)\n",
    "        df_scaled = pd.DataFrame(scaled_df, columns=df.columns)\n",
    "        targets = dataset.target\n",
    "        df_scaled['target'] = targets\n",
    "        columns = df_scaled.columns\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "        return X_train, X_test, y_train, y_test, columns, np.unique(targets)\n",
    "    else:\n",
    "        print(\"Incorrect dataset name\")\n",
    "        \n",
    "def parse_explanation(explanation, feature_names, epsilon=1e-6):\n",
    "    bounds = [[0, 1] for _ in range(len(feature_names))]\n",
    "    conditions = explanation\n",
    "\n",
    "    for condition in conditions:\n",
    "        condition_no_space = condition.replace(' ', '')  # for regex matching\n",
    "        # Check for double inequality\n",
    "        match = re.match(r'(\\d+\\.?\\d*)\\s*(<|<=)\\s*([^\\s<>]+)\\s*(<|<=)\\s*(\\d+\\.?\\d*)', condition_no_space)\n",
    "        \n",
    "        if match:\n",
    "            value_1, op1, feature_token, op2, value_2 = match.groups()\n",
    "            value_1 = float(value_1)\n",
    "            value_2 = float(value_2)\n",
    "            lower_bound = value_1 if op1 == '<=' else value_1 + epsilon\n",
    "            upper_bound = value_2 if op2 == '<=' else value_2\n",
    "            upper_bound = upper_bound if op2 == '<=' else upper_bound - epsilon\n",
    "\n",
    "            for idx, feature in enumerate(feature_names):\n",
    "                if feature.replace(\" \", \"\") in feature_token:\n",
    "                    bounds[idx] = [lower_bound, upper_bound]\n",
    "                    break\n",
    "            continue  # go to next condition\n",
    "\n",
    "        # Fallback to single operator logic\n",
    "        for idx, feature in enumerate(feature_names):\n",
    "            if feature in condition:\n",
    "                cond_clean = condition.replace('<=', ' LESS_EQUAL ').replace('>=', ' GREATER_EQUAL ')\n",
    "                cond_clean = cond_clean.replace('<', ' < ').replace('>', ' > ')\n",
    "                tokens = cond_clean.split()\n",
    "\n",
    "                tokens = ['<=' if token == 'LESS_EQUAL' else token for token in tokens]\n",
    "                tokens = ['>=' if token == 'GREATER_EQUAL' else token for token in tokens]\n",
    "\n",
    "                operator = None\n",
    "                operator_pos = None\n",
    "                for i, token in enumerate(tokens):\n",
    "                    if token in ['>', '>=', '<', '<=']:\n",
    "                        operator = token\n",
    "                        operator_pos = i\n",
    "                        break\n",
    "\n",
    "                value = None\n",
    "                if operator is not None and operator_pos is not None:\n",
    "                    for i in range(operator_pos + 1, len(tokens)):\n",
    "                        try:\n",
    "                            value = float(tokens[i])\n",
    "                            break\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "\n",
    "                if value is not None:\n",
    "                    if operator == '>':\n",
    "                        bounds[idx] = [value + epsilon, 1]\n",
    "                    elif operator == '>=':\n",
    "                        bounds[idx] = [value, 1]\n",
    "                    elif operator == '<':\n",
    "                        bounds[idx] = [0, value - epsilon]\n",
    "                    elif operator == '<=':\n",
    "                        bounds[idx] = [0, value]\n",
    "                else:\n",
    "                    print(f\"Could not extract numeric value from condition: '{condition}'\")\n",
    "\n",
    "    return np.array(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aad331f-2c7c-46a8-ac6a-2f9df2cc9db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mateus\\anaconda3\\Lib\\site-packages\\alibi\\explainers\\cem.py:35: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Iris\n",
      "Loaded model\n",
      "feature names:\n",
      " Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
      "       'petal width (cm)'],\n",
      "      dtype='object')\n",
      "class names:\n",
      " [0 1 2]\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n",
      "Could not find an anchor satisfying the 1 precision constraint. Now returning the best non-eligible result. The desired precision threshold might not be achieved due to the quantile-based discretisation of the numerical features. The resolution of the bins may be too large to find an anchor of required precision. Consider increasing the number of bins in `disc_perc`, but note that for some numerical distribution (e.g. skewed distribution) it may not help.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\n",
      "saved Iris_results.csv\n"
     ]
    }
   ],
   "source": [
    "from alibi.explainers import AnchorTabular\n",
    "\n",
    "def run_anchors(dataset_name, epsilon = 1e-6, verbose=0):\n",
    "\n",
    "    def predict_fn(x):\n",
    "        return clf.predict(x, verbose=0)\n",
    "    \n",
    "    print(dataset_name)\n",
    "    clf = tf.keras.models.load_model(f'new_models/{dataset_name}.h5', compile=False)\n",
    "    print(f'Loaded model')\n",
    "    test_dataset_df = pd.read_csv(f'{dataset_name}_results/{dataset_name}_X_test.csv')\n",
    "    X_train, X_test, y_train, y_test,feature_names, class_names = load_data(dataset_name)\n",
    "    if 'target' in feature_names:\n",
    "        feature_names = feature_names[feature_names != 'target']\n",
    "    print(f'feature names:\\n {feature_names}')\n",
    "    print(f'class names:\\n {class_names}')\n",
    "    #predict_fn = lambda x: clf.predict(x)\n",
    "    explainer = AnchorTabular(predict_fn, feature_names)\n",
    "    explainer.fit(X_train, disc_perc=(25, 50, 75))\n",
    "    coverages = []\n",
    "    errors = []\n",
    "    times = []\n",
    "    rsums = []\n",
    "    sizes = []\n",
    "    explanations = []\n",
    "    all_bounds = []\n",
    "    for idx in range(len(test_dataset_df)):\n",
    "        prediction = class_names[explainer.predictor(test_dataset_df.values[idx,:-1].reshape(1, -1))[0]]\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        explanation = explainer.explain(test_dataset_df.values[idx,:-1], threshold=1)\n",
    "        end =  time.perf_counter()\n",
    "        times.append(end - start)\n",
    "        size = 0\n",
    "        for feature_name in feature_names:\n",
    "            for anchor in explanation.anchor:\n",
    "                if feature_name in re.split(r' <= | >= | < | > ', anchor):\n",
    "                    size += 1\n",
    "        bounds = parse_explanation(explanation.anchor, feature_names, epsilon)\n",
    "        rsum = mymetrics.range_sum(bounds)\n",
    "        \n",
    "        coverage_df = mymetrics.calculate_coverage(test_dataset_df, bounds)\n",
    "        my_coverage = len(coverage_df)\n",
    "        error = len(coverage_df[coverage_df['target'] != prediction])\n",
    "        original_instance_df = pd.DataFrame(test_dataset_df.values[idx,:-1].reshape(1, -1), columns=feature_names)\n",
    "        original_instance_df['target'] = prediction\n",
    "        instance_coverage = len(mymetrics.calculate_coverage(original_instance_df, bounds))\n",
    "        if instance_coverage == 0:\n",
    "            my_coverage += 1\n",
    "        if verbose:\n",
    "            print('\\n\\nPrediction: ', prediction)\n",
    "            print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "            print(f'Bounds:\\n {bounds}')\n",
    "            print('Precision: %.2f' % explanation.precision)\n",
    "            print('Coverage: %.2f' % explanation.coverage)\n",
    "            print(f'Time: {times[-1]}')\n",
    "            print(f'My_coverage: {my_coverage}')      \n",
    "            if error > 0:    \n",
    "                print(f'errors: {error}')\n",
    "                print(f'explanation:\\n {bounds}')\n",
    "                display(coverage_df[coverage_df['target'] != prediction])\n",
    "        coverages.append(my_coverage)\n",
    "        errors.append(error)\n",
    "        rsums.append(rsum)\n",
    "        sizes.append(size)\n",
    "        explanations.append(explanation.anchor)\n",
    "        all_bounds.append(bounds)\n",
    "    print('END')\n",
    "    result_df = pd.DataFrame(columns=['coverage','errors','time'])\n",
    "    result_df['coverage'] = coverages\n",
    "    result_df['errors'] = errors\n",
    "    result_df['time'] = times\n",
    "    result_df['rsum'] = rsums\n",
    "    result_df['size'] = sizes\n",
    "    result_df.to_csv(f'./Anchors_results/{dataset_name}_results.csv',index=False)\n",
    "    print(f'saved {dataset_name}_results.csv')\n",
    "\n",
    "    anchors_exp_df = pd.DataFrame()\n",
    "    anchors_exp_df['Explanation'] = explanations\n",
    "    anchors_exp_df['Bounds'] = all_bounds\n",
    "    anchors_exp_df.to_csv(f'./Anchors_results/{dataset_name}_explanations.csv',index=False)\n",
    "    #return coverages,errors, times\n",
    "    explainer.save(f'Anchors_explainers/{dataset_name}_model')\n",
    "for dataset_name in ['Iris', 'Wine', 'Column', 'Pima', 'Parkinson', 'Breast_Cancer', 'Blood_Transfusion', 'Ionosphere', 'Glass', 'Climate', 'Modeling', 'Banknote', 'Sonar']:\n",
    "    run_anchors(dataset_name = dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed430cf4-4fe1-4826-a9de-95fc8a7e1728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786842</td>\n",
       "      <td>0.185771</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.278351</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.575862</td>\n",
       "      <td>0.419831</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.495268</td>\n",
       "      <td>0.291809</td>\n",
       "      <td>0.455285</td>\n",
       "      <td>0.849817</td>\n",
       "      <td>0.539943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.150198</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>0.613402</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.613924</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.621451</td>\n",
       "      <td>0.377133</td>\n",
       "      <td>0.577236</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.718260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.707895</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>0.314433</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.834483</td>\n",
       "      <td>0.702532</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.514196</td>\n",
       "      <td>0.470990</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.586081</td>\n",
       "      <td>0.718260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.597368</td>\n",
       "      <td>0.193676</td>\n",
       "      <td>0.417112</td>\n",
       "      <td>0.329897</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.489655</td>\n",
       "      <td>0.390295</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.296530</td>\n",
       "      <td>0.227816</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.549451</td>\n",
       "      <td>0.718260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.715789</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.561497</td>\n",
       "      <td>0.278351</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.558621</td>\n",
       "      <td>0.510549</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.441640</td>\n",
       "      <td>0.368601</td>\n",
       "      <td>0.544715</td>\n",
       "      <td>0.597070</td>\n",
       "      <td>0.743224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.807895</td>\n",
       "      <td>0.280632</td>\n",
       "      <td>0.502674</td>\n",
       "      <td>0.381443</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>0.679310</td>\n",
       "      <td>0.628692</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.621451</td>\n",
       "      <td>0.381399</td>\n",
       "      <td>0.626016</td>\n",
       "      <td>0.695971</td>\n",
       "      <td>0.878745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.797368</td>\n",
       "      <td>0.278656</td>\n",
       "      <td>0.668449</td>\n",
       "      <td>0.360825</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.558621</td>\n",
       "      <td>0.457806</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.264984</td>\n",
       "      <td>0.321672</td>\n",
       "      <td>0.471545</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.725392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.665789</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.288660</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.748276</td>\n",
       "      <td>0.622363</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.608833</td>\n",
       "      <td>0.413823</td>\n",
       "      <td>0.382114</td>\n",
       "      <td>0.772894</td>\n",
       "      <td>0.368759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.686842</td>\n",
       "      <td>0.466403</td>\n",
       "      <td>0.641711</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.593103</td>\n",
       "      <td>0.567511</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.325939</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.765568</td>\n",
       "      <td>0.404422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>0.689840</td>\n",
       "      <td>0.412371</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.493103</td>\n",
       "      <td>0.436709</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.495268</td>\n",
       "      <td>0.274744</td>\n",
       "      <td>0.447154</td>\n",
       "      <td>0.824176</td>\n",
       "      <td>0.350927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.721053</td>\n",
       "      <td>0.229249</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.335052</td>\n",
       "      <td>0.489130</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.516878</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.400631</td>\n",
       "      <td>0.428328</td>\n",
       "      <td>0.528455</td>\n",
       "      <td>0.608059</td>\n",
       "      <td>0.782454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.765789</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.486631</td>\n",
       "      <td>0.350515</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.675105</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.526814</td>\n",
       "      <td>0.650171</td>\n",
       "      <td>0.520325</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.700428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.618143</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.788644</td>\n",
       "      <td>0.505119</td>\n",
       "      <td>0.520325</td>\n",
       "      <td>0.600733</td>\n",
       "      <td>0.621969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.560526</td>\n",
       "      <td>0.320158</td>\n",
       "      <td>0.700535</td>\n",
       "      <td>0.412371</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.611814</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.757098</td>\n",
       "      <td>0.375427</td>\n",
       "      <td>0.447154</td>\n",
       "      <td>0.695971</td>\n",
       "      <td>0.646933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.179842</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.340206</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.506897</td>\n",
       "      <td>0.559072</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.593060</td>\n",
       "      <td>0.368601</td>\n",
       "      <td>0.617886</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.703994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.836842</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.577540</td>\n",
       "      <td>0.427835</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.644828</td>\n",
       "      <td>0.487342</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.264984</td>\n",
       "      <td>0.337884</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.754579</td>\n",
       "      <td>0.572040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.244737</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.502674</td>\n",
       "      <td>0.536082</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391167</td>\n",
       "      <td>0.164676</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.433666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.215415</td>\n",
       "      <td>0.534759</td>\n",
       "      <td>0.340206</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.496552</td>\n",
       "      <td>0.495781</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>0.492114</td>\n",
       "      <td>0.218430</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.586081</td>\n",
       "      <td>0.507846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.534759</td>\n",
       "      <td>0.438144</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.648276</td>\n",
       "      <td>0.601266</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.485804</td>\n",
       "      <td>0.479522</td>\n",
       "      <td>0.495935</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.882311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.211462</td>\n",
       "      <td>0.561497</td>\n",
       "      <td>0.510309</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.593103</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.457413</td>\n",
       "      <td>0.325939</td>\n",
       "      <td>0.455285</td>\n",
       "      <td>0.805861</td>\n",
       "      <td>0.457917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.179842</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.381443</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.506897</td>\n",
       "      <td>0.440928</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.324921</td>\n",
       "      <td>0.253413</td>\n",
       "      <td>0.520325</td>\n",
       "      <td>0.454212</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.223320</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.072165</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.804416</td>\n",
       "      <td>0.530717</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.633700</td>\n",
       "      <td>0.905136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.878947</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>0.319588</td>\n",
       "      <td>0.467391</td>\n",
       "      <td>0.989655</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.558360</td>\n",
       "      <td>0.556314</td>\n",
       "      <td>0.308943</td>\n",
       "      <td>0.798535</td>\n",
       "      <td>0.857347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.536842</td>\n",
       "      <td>0.150198</td>\n",
       "      <td>0.395722</td>\n",
       "      <td>0.252577</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.489655</td>\n",
       "      <td>0.485232</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.302839</td>\n",
       "      <td>0.206485</td>\n",
       "      <td>0.569106</td>\n",
       "      <td>0.520147</td>\n",
       "      <td>0.529244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.744737</td>\n",
       "      <td>0.120553</td>\n",
       "      <td>0.486631</td>\n",
       "      <td>0.278351</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.592827</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>0.430894</td>\n",
       "      <td>0.835165</td>\n",
       "      <td>0.547076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.203557</td>\n",
       "      <td>0.395722</td>\n",
       "      <td>0.329897</td>\n",
       "      <td>0.402174</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.561181</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.511041</td>\n",
       "      <td>0.320819</td>\n",
       "      <td>0.325203</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.432953</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.177866</td>\n",
       "      <td>0.791444</td>\n",
       "      <td>0.252577</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.558621</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.299685</td>\n",
       "      <td>0.283276</td>\n",
       "      <td>0.495935</td>\n",
       "      <td>0.553114</td>\n",
       "      <td>0.429387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.211462</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>0.340206</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.644828</td>\n",
       "      <td>0.542194</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.331230</td>\n",
       "      <td>0.513652</td>\n",
       "      <td>0.650407</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.736091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.229249</td>\n",
       "      <td>0.770053</td>\n",
       "      <td>0.453608</td>\n",
       "      <td>0.402174</td>\n",
       "      <td>0.679310</td>\n",
       "      <td>0.554852</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.425868</td>\n",
       "      <td>0.274744</td>\n",
       "      <td>0.626016</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.454351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.734211</td>\n",
       "      <td>0.199605</td>\n",
       "      <td>0.566845</td>\n",
       "      <td>0.175258</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717300</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.460568</td>\n",
       "      <td>0.492321</td>\n",
       "      <td>0.430894</td>\n",
       "      <td>0.728938</td>\n",
       "      <td>0.650499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.718421</td>\n",
       "      <td>0.156126</td>\n",
       "      <td>0.716578</td>\n",
       "      <td>0.458763</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.679310</td>\n",
       "      <td>0.506329</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.296530</td>\n",
       "      <td>0.351536</td>\n",
       "      <td>0.626016</td>\n",
       "      <td>0.633700</td>\n",
       "      <td>0.682596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.209486</td>\n",
       "      <td>0.689840</td>\n",
       "      <td>0.432990</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.472414</td>\n",
       "      <td>0.462025</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.356467</td>\n",
       "      <td>0.249147</td>\n",
       "      <td>0.504065</td>\n",
       "      <td>0.586081</td>\n",
       "      <td>0.582739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.223320</td>\n",
       "      <td>0.582888</td>\n",
       "      <td>0.206186</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.524138</td>\n",
       "      <td>0.459916</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.495268</td>\n",
       "      <td>0.338737</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.721826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.797368</td>\n",
       "      <td>0.175889</td>\n",
       "      <td>0.491979</td>\n",
       "      <td>0.278351</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.597046</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.533123</td>\n",
       "      <td>0.372867</td>\n",
       "      <td>0.495935</td>\n",
       "      <td>0.893773</td>\n",
       "      <td>0.358060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.572193</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.573840</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.593060</td>\n",
       "      <td>0.372014</td>\n",
       "      <td>0.455285</td>\n",
       "      <td>0.970696</td>\n",
       "      <td>0.561341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.755263</td>\n",
       "      <td>0.185771</td>\n",
       "      <td>0.406417</td>\n",
       "      <td>0.278351</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.731034</td>\n",
       "      <td>0.643460</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.545741</td>\n",
       "      <td>0.411263</td>\n",
       "      <td>0.349593</td>\n",
       "      <td>0.754579</td>\n",
       "      <td>0.504280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.594737</td>\n",
       "      <td>0.243083</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.319588</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.609705</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.402730</td>\n",
       "      <td>0.479675</td>\n",
       "      <td>0.575092</td>\n",
       "      <td>0.707561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.621053</td>\n",
       "      <td>0.203557</td>\n",
       "      <td>0.673797</td>\n",
       "      <td>0.283505</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.644828</td>\n",
       "      <td>0.548523</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.328076</td>\n",
       "      <td>0.300341</td>\n",
       "      <td>0.357724</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.654066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.834211</td>\n",
       "      <td>0.201581</td>\n",
       "      <td>0.582888</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.789655</td>\n",
       "      <td>0.643460</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.492114</td>\n",
       "      <td>0.466724</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.578755</td>\n",
       "      <td>0.835949</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.146245</td>\n",
       "      <td>0.513369</td>\n",
       "      <td>0.319588</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.420690</td>\n",
       "      <td>0.440928</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.365931</td>\n",
       "      <td>0.317406</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.567766</td>\n",
       "      <td>0.714693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.665789</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.510309</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.682759</td>\n",
       "      <td>0.514768</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.643533</td>\n",
       "      <td>0.424061</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.644689</td>\n",
       "      <td>0.600571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.807895</td>\n",
       "      <td>0.252964</td>\n",
       "      <td>0.556150</td>\n",
       "      <td>0.422680</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.610345</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.621451</td>\n",
       "      <td>0.419795</td>\n",
       "      <td>0.479675</td>\n",
       "      <td>0.542125</td>\n",
       "      <td>0.557775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.221344</td>\n",
       "      <td>0.534759</td>\n",
       "      <td>0.309278</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.562069</td>\n",
       "      <td>0.535865</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.403785</td>\n",
       "      <td>0.215017</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.539943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid       ash  alcalinity_of_ash  magnesium  \\\n",
       "0   0.786842    0.185771  0.454545           0.278351   0.282609   \n",
       "1   0.710526    0.150198  0.716578           0.613402   0.336957   \n",
       "2   0.707895    0.136364  0.609626           0.314433   0.413043   \n",
       "3   0.597368    0.193676  0.417112           0.329897   0.260870   \n",
       "4   0.715789    0.195652  0.561497           0.278351   0.206522   \n",
       "5   0.807895    0.280632  0.502674           0.381443   0.380435   \n",
       "6   0.797368    0.278656  0.668449           0.360825   0.554348   \n",
       "7   0.665789    0.191700  0.508021           0.288660   0.510870   \n",
       "8   0.686842    0.466403  0.641711           0.237113   0.500000   \n",
       "9   0.500000    0.604743  0.689840           0.412371   0.347826   \n",
       "10  0.721053    0.229249  0.705882           0.335052   0.489130   \n",
       "11  0.765789    0.195652  0.486631           0.350515   0.413043   \n",
       "12  0.531579    0.195652  0.363636           0.092784   0.239130   \n",
       "13  0.560526    0.320158  0.700535           0.412371   0.336957   \n",
       "14  0.736842    0.179842  0.663102           0.340206   0.260870   \n",
       "15  0.836842    0.652174  0.577540           0.427835   0.445652   \n",
       "16  0.244737    0.069170  0.502674           0.536082   0.336957   \n",
       "17  0.697368    0.215415  0.534759           0.340206   0.369565   \n",
       "18  0.671053    0.181818  0.534759           0.438144   0.391304   \n",
       "19  0.644737    0.211462  0.561497           0.510309   0.326087   \n",
       "20  0.531579    0.179842  0.636364           0.381443   0.304348   \n",
       "21  0.881579    0.223320  0.545455           0.072165   0.347826   \n",
       "22  0.878947    0.239130  0.609626           0.319588   0.467391   \n",
       "23  0.536842    0.150198  0.395722           0.252577   0.304348   \n",
       "24  0.744737    0.120553  0.486631           0.278351   0.304348   \n",
       "25  0.531579    0.203557  0.395722           0.329897   0.402174   \n",
       "26  0.592105    0.177866  0.791444           0.252577   0.434783   \n",
       "27  0.684211    0.211462  0.716578           0.340206   0.456522   \n",
       "28  0.747368    0.229249  0.770053           0.453608   0.402174   \n",
       "29  0.734211    0.199605  0.566845           0.175258   0.445652   \n",
       "30  0.718421    0.156126  0.716578           0.458763   0.673913   \n",
       "31  0.652632    0.209486  0.689840           0.432990   0.434783   \n",
       "32  0.884211    0.223320  0.582888           0.206186   0.282609   \n",
       "33  0.797368    0.175889  0.491979           0.278351   0.608696   \n",
       "34  0.842105    0.191700  0.572193           0.257732   0.619565   \n",
       "35  0.755263    0.185771  0.406417           0.278351   0.336957   \n",
       "36  0.594737    0.243083  0.705882           0.319588   0.347826   \n",
       "37  0.621053    0.203557  0.673797           0.283505   0.250000   \n",
       "38  0.834211    0.201581  0.582888           0.237113   0.456522   \n",
       "39  0.813158    0.146245  0.513369           0.319588   0.271739   \n",
       "40  0.665789    0.195652  0.588235           0.510309   0.500000   \n",
       "41  0.807895    0.252964  0.556150           0.422680   0.358696   \n",
       "42  0.705263    0.221344  0.534759           0.309278   0.336957   \n",
       "\n",
       "    total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "0        0.575862    0.419831              0.245283         0.495268   \n",
       "1        0.696552    0.613924              0.301887         0.621451   \n",
       "2        0.834483    0.702532              0.113208         0.514196   \n",
       "3        0.489655    0.390295              0.264151         0.296530   \n",
       "4        0.558621    0.510549              0.301887         0.441640   \n",
       "5        0.679310    0.628692              0.169811         0.621451   \n",
       "6        0.558621    0.457806              0.339623         0.264984   \n",
       "7        0.748276    0.622363              0.396226         0.608833   \n",
       "8        0.593103    0.567511              0.075472         0.394322   \n",
       "9        0.493103    0.436709              0.226415         0.495268   \n",
       "10       0.696552    0.516878              0.490566         0.400631   \n",
       "11       0.655172    0.675105              0.358491         0.526814   \n",
       "12       0.600000    0.618143              0.075472         0.788644   \n",
       "13       0.627586    0.611814              0.320755         0.757098   \n",
       "14       0.506897    0.559072              0.169811         0.593060   \n",
       "15       0.644828    0.487342              0.320755         0.264984   \n",
       "16       0.827586    0.379747              0.000000         0.391167   \n",
       "17       0.496552    0.495781              0.547170         0.492114   \n",
       "18       0.648276    0.601266              0.169811         0.485804   \n",
       "19       0.593103    0.556962              0.245283         0.457413   \n",
       "20       0.506897    0.440928              0.301887         0.324921   \n",
       "21       0.800000    0.696203              0.301887         0.804416   \n",
       "22       0.989655    0.664557              0.207547         0.558360   \n",
       "23       0.489655    0.485232              0.283019         0.302839   \n",
       "24       0.689655    0.592827              0.169811         0.454259   \n",
       "25       0.696552    0.561181              0.283019         0.511041   \n",
       "26       0.558621    0.493671              0.396226         0.299685   \n",
       "27       0.644828    0.542194              0.320755         0.331230   \n",
       "28       0.679310    0.554852              0.452830         0.425868   \n",
       "29       1.000000    0.717300              0.358491         0.460568   \n",
       "30       0.679310    0.506329              0.698113         0.296530   \n",
       "31       0.472414    0.462025              0.301887         0.356467   \n",
       "32       0.524138    0.459916              0.320755         0.495268   \n",
       "33       0.696552    0.597046              0.207547         0.533123   \n",
       "34       0.627586    0.573840              0.283019         0.593060   \n",
       "35       0.731034    0.643460              0.150943         0.545741   \n",
       "36       0.696552    0.609705              0.339623         0.394322   \n",
       "37       0.644828    0.548523              0.396226         0.328076   \n",
       "38       0.789655    0.643460              0.396226         0.492114   \n",
       "39       0.420690    0.440928              0.245283         0.365931   \n",
       "40       0.682759    0.514768              0.132075         0.643533   \n",
       "41       0.610345    0.544304              0.358491         0.621451   \n",
       "42       0.562069    0.535865              0.264151         0.403785   \n",
       "\n",
       "    color_intensity       hue  od280/od315_of_diluted_wines   proline  target  \n",
       "0          0.291809  0.455285                      0.849817  0.539943       0  \n",
       "1          0.377133  0.577236                      0.527473  0.718260       0  \n",
       "2          0.470990  0.333333                      0.586081  0.718260       0  \n",
       "3          0.227816  0.439024                      0.549451  0.718260       0  \n",
       "4          0.368601  0.544715                      0.597070  0.743224       0  \n",
       "5          0.381399  0.626016                      0.695971  0.878745       0  \n",
       "6          0.321672  0.471545                      0.846154  0.725392       0  \n",
       "7          0.413823  0.382114                      0.772894  0.368759       0  \n",
       "8          0.325939  0.390244                      0.765568  0.404422       0  \n",
       "9          0.274744  0.447154                      0.824176  0.350927       0  \n",
       "10         0.428328  0.528455                      0.608059  0.782454       0  \n",
       "11         0.650171  0.520325                      0.670330  0.700428       0  \n",
       "12         0.505119  0.520325                      0.600733  0.621969       0  \n",
       "13         0.375427  0.447154                      0.695971  0.646933       0  \n",
       "14         0.368601  0.617886                      0.769231  0.703994       0  \n",
       "15         0.337884  0.317073                      0.754579  0.572040       0  \n",
       "16         0.164676  0.414634                      0.681319  0.433666       0  \n",
       "17         0.218430  0.609756                      0.586081  0.507846       0  \n",
       "18         0.479522  0.495935                      0.589744  0.882311       0  \n",
       "19         0.325939  0.455285                      0.805861  0.457917       0  \n",
       "20         0.253413  0.520325                      0.454212  0.589872       0  \n",
       "21         0.530717  0.585366                      0.633700  0.905136       0  \n",
       "22         0.556314  0.308943                      0.798535  0.857347       0  \n",
       "23         0.206485  0.569106                      0.520147  0.529244       0  \n",
       "24         0.506826  0.430894                      0.835165  0.547076       0  \n",
       "25         0.320819  0.325203                      0.761905  0.432953       0  \n",
       "26         0.283276  0.495935                      0.553114  0.429387       0  \n",
       "27         0.513652  0.650407                      0.589744  0.736091       0  \n",
       "28         0.274744  0.626016                      0.780220  0.454351       0  \n",
       "29         0.492321  0.430894                      0.728938  0.650499       0  \n",
       "30         0.351536  0.626016                      0.633700  0.682596       0  \n",
       "31         0.249147  0.504065                      0.586081  0.582739       0  \n",
       "32         0.338737  0.439024                      0.846154  0.721826       0  \n",
       "33         0.372867  0.495935                      0.893773  0.358060       0  \n",
       "34         0.372014  0.455285                      0.970696  0.561341       0  \n",
       "35         0.411263  0.349593                      0.754579  0.504280       0  \n",
       "36         0.402730  0.479675                      0.575092  0.707561       0  \n",
       "37         0.300341  0.357724                      0.714286  0.654066       0  \n",
       "38         0.466724  0.463415                      0.578755  0.835949       0  \n",
       "39         0.317406  0.560976                      0.567766  0.714693       0  \n",
       "40         0.424061  0.406504                      0.644689  0.600571       0  \n",
       "41         0.419795  0.479675                      0.542125  0.557775       0  \n",
       "42         0.215017  0.512195                      1.000000  0.539943       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_df[test_dataset_df['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3945a-bdd2-421a-9f05-37b5401ce1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
