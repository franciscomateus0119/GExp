{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50f05f7-5f70-44e3-a154-d448a34155d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import docplex\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utility\n",
    "import copy\n",
    "import mlp_explainer\n",
    "import mymetrics\n",
    "import time\n",
    "import dataframe_image as dfi\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from milp import codify_network\n",
    "from teste import get_minimal_explanation\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b77688-1364-4f79-b3b1-9f30f5fba025",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0             0.222222          0.625000           0.067797          0.041667   \n",
       "1             0.166667          0.416667           0.067797          0.041667   \n",
       "2             0.111111          0.500000           0.050847          0.041667   \n",
       "3             0.083333          0.458333           0.084746          0.041667   \n",
       "4             0.194444          0.666667           0.067797          0.041667   \n",
       "..                 ...               ...                ...               ...   \n",
       "145           0.666667          0.416667           0.711864          0.916667   \n",
       "146           0.555556          0.208333           0.677966          0.750000   \n",
       "147           0.611111          0.416667           0.711864          0.791667   \n",
       "148           0.527778          0.583333           0.745763          0.916667   \n",
       "149           0.444444          0.416667           0.694915          0.708333   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SklearnDatasets\n",
    "dataset = datasets.load_iris()\n",
    "df = pd.DataFrame(dataset.data, columns = dataset.feature_names)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(dataset.data)\n",
    "scaled_df = scaler.transform(dataset.data)\n",
    "lower_bound = scaled_df.min()\n",
    "upper_bound = scaled_df.max()\n",
    "print(lower_bound, upper_bound)\n",
    "df_scaled = pd.DataFrame(scaled_df, columns=df.columns)\n",
    "targets = dataset.target\n",
    "df_scaled['target'] = targets\n",
    "columns = df_scaled.columns\n",
    "dir_path = 'Iris'\n",
    "dataset_name = 'Iris'\n",
    "display(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482f0ed7-ffeb-4f9b-a7d1-4590caa730d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.3,random_state=50,stratify=targets)\n",
    "X = np.concatenate((X_train,X_test),axis=0)\n",
    "y = np.concatenate((y_train,y_test),axis=0)\n",
    "\n",
    "training_data = pd.DataFrame(X_train, columns = columns[:-1])\n",
    "training_data[columns[-1]] = y_train\n",
    "testing_data = pd.DataFrame(X_test, columns = columns[:-1])\n",
    "testing_data[columns[-1]] = y_test\n",
    "dataframe = pd.concat([training_data, testing_data])\n",
    "data = dataframe.to_numpy()\n",
    "n_classes = dataframe['target'].nunique()\n",
    "\n",
    "original_bounds = [[dataframe[dataframe.columns[i]].min(),dataframe[dataframe.columns[i]].max()] for i in range(len(dataframe.columns[:-1]))]\n",
    "keras_model = tf.keras.models.load_model(f'new_models/{dataset_name}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0271f8c-4ee7-440b-81c8-f6cbb73cbdc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mp_model, output_bounds = codify_network(keras_model, dataframe, 'fischetti', relax_constraints=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a74a378-6142-4dd5-9cbe-5cfe7b52b5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test Data: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "possible_classes = np.unique(y_test)\n",
    "class_indexes = []\n",
    "class_predictions = []\n",
    "for i in range(n_classes):\n",
    "    class_indexes.append([])\n",
    "    class_predictions.append([])\n",
    "possible_classes, class_indexes, class_predictions\n",
    "data = testing_data.to_numpy()\n",
    "for i in range(len(data)):\n",
    "    predictions.append(mlp_explainer.model_classification_output(k_model=keras_model, net_input=data[i, :-1])[1].numpy())    \n",
    "    for j,p_class in enumerate(possible_classes):\n",
    "        if predictions[-1] == p_class:\n",
    "            class_indexes[j].append(i)\n",
    "            class_predictions[j].append(data[i, :-1])\n",
    "print(\"Accuracy Test Data:\", metrics.accuracy_score(testing_data.to_numpy()[:, -1], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7224a582-1645-4070-bab2-0a2f7ebf327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(testing_data.columns)\n",
    "if 'target' not in cols:\n",
    "    cols.append('target')\n",
    "predicted_dataset = []\n",
    "for i,pos_class in enumerate(np.unique(y_test)):\n",
    "    for instance in (testing_data.to_numpy()[:, :-1][class_indexes[i]]):\n",
    "        instance = np.append(instance, pos_class.astype('int'))\n",
    "        predicted_dataset.append(instance)\n",
    "predicted_dataset = np.asarray(predicted_dataset)\n",
    "pred_dataset_df = pd.DataFrame(predicted_dataset, columns=cols)\n",
    "pred_dataset_df['target'] = pred_dataset_df['target'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1887131a-f006-46c8-8f7d-97f869cd7006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_dataframes = []\n",
    "times_onestep = []\n",
    "sizes_onestep = []\n",
    "rsum_onestep = []\n",
    "coverage_onestep = []\n",
    "pos_exp_onestep = []\n",
    "neg_exp_onestep = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d16944-1ca7-4e33-bd38-5b6d8f06fb95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a548b2f0-9f0e-4b19-9751-b6aae41b93aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "onestep_explanations = []\n",
    "for j in range(len(pred_dataset_df['target'].unique())):\n",
    "    for i, sample in enumerate((testing_data.to_numpy()[:, :-1][class_indexes[j]])):\n",
    "        start = time.perf_counter()\n",
    "        explanation, minimal = mlp_explainer.run_explanation(sample = sample, n_classes=n_classes, kmodel=keras_model, model=mp_model, output_bounds=output_bounds, og_bounds=original_bounds, enable_log=False,\n",
    "                                                             )\n",
    "        end = time.perf_counter()\n",
    "        onestep_explanations.append(explanation)\n",
    "        times_onestep.append(end-start)\n",
    "        sizes_onestep.append(len(minimal))\n",
    "        rsum_onestep.append(mymetrics.range_sum(onestep_explanations[-1]))\n",
    "        coverage_onestep.append(len(mymetrics.calculate_coverage(testing_data, onestep_explanations[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "898a1dfb-ad29-4e80-9262-4f0f2f1a5800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Onestep_MEAN</th>\n",
       "      <th>Onestep_STD</th>\n",
       "      <th>Twostep_MEAN</th>\n",
       "      <th>Twostep_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Time</td>\n",
       "      <td>0.193568</td>\n",
       "      <td>0.053418</td>\n",
       "      <td>0.247015</td>\n",
       "      <td>0.059288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Size</td>\n",
       "      <td>2.911111</td>\n",
       "      <td>0.462948</td>\n",
       "      <td>2.911111</td>\n",
       "      <td>0.462948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ranges_Sum</td>\n",
       "      <td>2.001444</td>\n",
       "      <td>0.149471</td>\n",
       "      <td>1.947408</td>\n",
       "      <td>0.178696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coverage</td>\n",
       "      <td>4.511111</td>\n",
       "      <td>3.493627</td>\n",
       "      <td>5.822222</td>\n",
       "      <td>4.202057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Metric Onestep_MEAN Onestep_STD Twostep_MEAN Twostep_STD\n",
       "0        Time     0.193568    0.053418     0.247015    0.059288\n",
       "1        Size     2.911111    0.462948     2.911111    0.462948\n",
       "2  Ranges_Sum     2.001444    0.149471     1.947408    0.178696\n",
       "3    Coverage     4.511111    3.493627     5.822222    4.202057"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_values = [0.50] #[0.25, 0.50, 0.75]\n",
    "for p_value in p_values:\n",
    "    print(f\"p = {p_value}\")\n",
    "    times_twostep = []\n",
    "    sizes_twostep = []\n",
    "    rsum_twostep = []\n",
    "    coverage_twostep = []\n",
    "    twostep_explanations = []\n",
    "    for j in range(len(pred_dataset_df['target'].unique())):\n",
    "        for i, sample in enumerate((testing_data.to_numpy()[:, :-1][class_indexes[j]])):\n",
    "            start = time.perf_counter()\n",
    "            \n",
    "            explanation, minimal = mlp_explainer.run_explanation_doublestep(sample = sample, n_classes=n_classes, kmodel=keras_model, model=mp_model, output_bounds=output_bounds, og_bounds=original_bounds, p=p_value)\n",
    "            end = time.perf_counter()\n",
    "            twostep_explanations.append(explanation)\n",
    "            times_twostep.append(end-start)\n",
    "            sizes_twostep.append(len(minimal))\n",
    "            rsum_twostep.append(mymetrics.range_sum(twostep_explanations[-1]))\n",
    "            \n",
    "            coverage_twostep.append(len(mymetrics.calculate_coverage(testing_data, twostep_explanations[-1])))\n",
    "\n",
    "    time_mean_twostep = sum(times_twostep)/len(times_twostep)\n",
    "    time_std_twostep = np.std(times_twostep)\n",
    "    sizes_mean_twostep = sum(sizes_twostep)/len(sizes_twostep)\n",
    "    sizes_std_twostep = np.std(sizes_twostep)\n",
    "    rsum_mean_twostep = sum(rsum_twostep)/len(rsum_twostep)\n",
    "    rsum_std_twostep = np.std(rsum_twostep)\n",
    "\n",
    "    coverage_mean_twostep = sum(coverage_twostep)/len(coverage_twostep)\n",
    "    coverage_std_twostep = np.std(coverage_twostep)\n",
    "\n",
    "    time_mean_onestep = sum(times_onestep)/len(times_onestep)\n",
    "    time_std_onestep = np.std(times_onestep)\n",
    "    sizes_mean_onestep = sum(sizes_onestep)/len(sizes_onestep)\n",
    "    sizes_std_onestep = np.std(sizes_onestep)\n",
    "    rsum_mean_onestep = sum(rsum_onestep)/len(rsum_onestep)\n",
    "    rsum_std_onestep = np.std(rsum_onestep)\n",
    "\n",
    "    coverage_mean_onestep = sum(coverage_onestep)/len(coverage_onestep)\n",
    "    coverage_std_onestep = np.std(coverage_onestep)\n",
    "\n",
    "    all_metrics_names = ['Metric','Onestep_MEAN','Onestep_STD','Twostep_MEAN','Twostep_STD']\n",
    "\n",
    "    all_metrics_mean_df  = pd.DataFrame(columns=all_metrics_names)\n",
    "    pattern_row = ['Time',time_mean_onestep, time_std_onestep, time_mean_twostep,time_std_twostep]\n",
    "    all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "    pattern_row = ['Size', sizes_mean_onestep, sizes_std_onestep, sizes_mean_twostep,sizes_std_twostep]\n",
    "    all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "    pattern_row = ['Ranges_Sum', rsum_mean_onestep, rsum_std_onestep, rsum_mean_twostep,rsum_std_twostep]\n",
    "    all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "    pattern_row = ['Coverage', coverage_mean_onestep, coverage_std_onestep, coverage_mean_twostep,coverage_std_twostep]\n",
    "    all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "    metrics_dataframes.append(all_metrics_mean_df)\n",
    "\n",
    "    display(all_metrics_mean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "022a68dc-8733-47be-ad3f-5954ca949da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dfi.export(all_metrics_mean_df, './saved_dataframe_image/'+dataset_name +\"_\"+ str(p_values[0])+'.jpg')\n",
    "# all_metrics_mean_df.to_csv('./saved_dataframe_csv/'+dataset_name +\"_\"+ str(p_values[0])+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3941299-656a-4b58-a124-0bd53086e746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
