{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50f05f7-5f70-44e3-a154-d448a34155d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import docplex\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utility\n",
    "import copy\n",
    "import mlp_explainer\n",
    "import mymetrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from milp import codify_network\n",
    "from teste import get_minimal_explanation\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import dataframe_image as dfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b77688-1364-4f79-b3b1-9f30f5fba025",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0000000000000002\n",
      "Original Targets:  [0 1] \n",
      "Desired Targets: [0,1]\n",
      "Is original the desired [0, 1]?  True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0       0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1       0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2       0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3       0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4       0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564     0.690000      0.428813        0.678668   0.566490         0.526948   \n",
       "565     0.622320      0.626987        0.604036   0.474019         0.407782   \n",
       "566     0.455251      0.621238        0.445788   0.303118         0.288165   \n",
       "567     0.644564      0.663510        0.665538   0.475716         0.588336   \n",
       "568     0.036869      0.501522        0.028540   0.015907         0.000000   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.792037        0.703140             0.731113       0.686364   \n",
       "1            0.181768        0.203608             0.348757       0.379798   \n",
       "2            0.431017        0.462512             0.635686       0.509596   \n",
       "3            0.811361        0.565604             0.522863       0.776263   \n",
       "4            0.347893        0.463918             0.518390       0.378283   \n",
       "..                ...             ...                  ...            ...   \n",
       "564          0.296055        0.571462             0.690358       0.336364   \n",
       "565          0.257714        0.337395             0.486630       0.349495   \n",
       "566          0.254340        0.216753             0.263519       0.267677   \n",
       "567          0.790197        0.823336             0.755467       0.675253   \n",
       "568          0.074351        0.000000             0.000000       0.266162   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                  0.605518  ...       0.141525         0.668310    0.450698   \n",
       "1                  0.141323  ...       0.303571         0.539818    0.435214   \n",
       "2                  0.211247  ...       0.360075         0.508442    0.374508   \n",
       "3                  1.000000  ...       0.385928         0.241347    0.094008   \n",
       "4                  0.186816  ...       0.123934         0.506948    0.341575   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                0.132056  ...       0.383262         0.576174    0.452664   \n",
       "565                0.113100  ...       0.699094         0.520892    0.379915   \n",
       "566                0.137321  ...       0.589019         0.379949    0.230731   \n",
       "567                0.425442  ...       0.730277         0.668310    0.402035   \n",
       "568                0.187026  ...       0.489072         0.043578    0.020497   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0            0.601136           0.619292         0.568610   \n",
       "1            0.347553           0.154563         0.192971   \n",
       "2            0.483590           0.385375         0.359744   \n",
       "3            0.915472           0.814012         0.548642   \n",
       "4            0.437364           0.172415         0.319489   \n",
       "..                ...                ...              ...   \n",
       "564          0.461137           0.178527         0.328035   \n",
       "565          0.300007           0.159997         0.256789   \n",
       "566          0.282177           0.273705         0.271805   \n",
       "567          0.619626           0.815758         0.749760   \n",
       "568          0.124084           0.036043         0.000000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                0.912027        0.598462                 0.418864       0  \n",
       "1                0.639175        0.233590                 0.222878       0  \n",
       "2                0.835052        0.403706                 0.213433       0  \n",
       "3                0.884880        1.000000                 0.773711       0  \n",
       "4                0.558419        0.157500                 0.142595       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564              0.761512        0.097575                 0.105667       0  \n",
       "565              0.559450        0.198502                 0.074315       0  \n",
       "566              0.487285        0.128721                 0.151909       0  \n",
       "567              0.910653        0.497142                 0.452315       0  \n",
       "568              0.000000        0.257441                 0.100682       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SklearnDatasets\n",
    "dataset = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(dataset.data, columns = dataset.feature_names)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(dataset.data)\n",
    "scaled_df = scaler.transform(dataset.data)\n",
    "lower_bound = scaled_df.min()\n",
    "upper_bound = scaled_df.max()\n",
    "print(lower_bound, upper_bound)\n",
    "df_scaled = pd.DataFrame(scaled_df, columns=df.columns)\n",
    "targets = (utility.check_targets_0_1(np.where(dataset.target == dataset.target[0],0,1))).astype(np.int32)\n",
    "df_scaled['target'] = targets\n",
    "columns = df_scaled.columns\n",
    "dir_path = 'Breast_Cancer'\n",
    "dataset_name = 'Breast_Cancer'\n",
    "display(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482f0ed7-ffeb-4f9b-a7d1-4590caa730d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.3,random_state=50,stratify=targets)\n",
    "X = np.concatenate((X_train,X_test),axis=0)\n",
    "y = np.concatenate((y_train,y_test),axis=0)\n",
    "\n",
    "training_data = pd.DataFrame(X_train, columns = columns[:-1])\n",
    "training_data[columns[-1]] = y_train\n",
    "testing_data = pd.DataFrame(X_test, columns = columns[:-1])\n",
    "testing_data[columns[-1]] = y_test\n",
    "dataframe = pd.concat([training_data, testing_data])\n",
    "data = dataframe.to_numpy()\n",
    "n_classes = dataframe['target'].nunique()\n",
    "\n",
    "original_bounds = [[dataframe[dataframe.columns[i]].min(),dataframe[dataframe.columns[i]].max()] for i in range(len(dataframe.columns[:-1]))]\n",
    "keras_model = tf.keras.models.load_model(f'new_models/{dataset_name}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0271f8c-4ee7-440b-81c8-f6cbb73cbdc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mp_model, output_bounds = codify_network(keras_model, dataframe, 'fischetti', relax_constraints=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df0fdeab-f0c7-4079-ae50-b90a8262b0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test Data: 0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "negative_predictions = []\n",
    "positive_predictions = []\n",
    "negative_indexes = []\n",
    "positive_indexes = []\n",
    "data = testing_data.to_numpy()\n",
    "for i in range(len(data)):\n",
    "    predictions.append(mlp_explainer.model_classification_output(k_model=keras_model, net_input=data[i, :-1])[1].numpy())\n",
    "    if predictions[-1] == 0:\n",
    "        negative_indexes.append(i)\n",
    "        negative_predictions.append(data[i, :-1])\n",
    "    else:\n",
    "        positive_indexes.append(i)\n",
    "        positive_predictions.append(data[i, :-1])\n",
    "print(\"Accuracy Test Data:\", metrics.accuracy_score(testing_data.to_numpy()[:, -1], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c828902-07c9-472f-af54-f1d7bcf8568d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = list(testing_data.columns)\n",
    "if 'target' not in cols:\n",
    "    cols.append('target')\n",
    "predicted_dataset = []\n",
    "classes = np.array([0, 1],dtype='int')\n",
    "for instance in (testing_data.to_numpy()[:, :-1][negative_indexes]):\n",
    "    instance = np.append(instance, classes[0].astype('int'))\n",
    "    predicted_dataset.append(instance)\n",
    "for instance in (testing_data.to_numpy()[:, :-1][positive_indexes]):\n",
    "    instance = np.append(instance, classes[1])\n",
    "    predicted_dataset.append(instance)\n",
    "predicted_dataset = np.asarray(predicted_dataset)\n",
    "pred_dataset_df = pd.DataFrame(predicted_dataset, columns=cols)\n",
    "pred_dataset_df['target'] = pred_dataset_df['target'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1887131a-f006-46c8-8f7d-97f869cd7006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_dataframes = []\n",
    "times_direct = []\n",
    "sizes_direct = []\n",
    "diagonals_direct = []\n",
    "rsum_direct = []\n",
    "n_feat_ranges_direct = []\n",
    "coverage_direct = []\n",
    "accuracy_direct = []\n",
    "pos_exp_direct = []\n",
    "neg_exp_direct = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d16944-1ca7-4e33-bd38-5b6d8f06fb95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 1.0],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0000000000000002],\n",
       " [0.0, 1.0],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 1.0],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 0.9999999999999998],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 1.0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcadc0cf-f635-424a-873a-c4d0ae0e284a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "negative_direct_explanations = []\n",
    "coverage_direct = []\n",
    "accuracy_direct = []\n",
    "for i, sample in enumerate((testing_data.to_numpy()[:, :-1][negative_indexes])):\n",
    "    start = time.perf_counter()\n",
    "    explanation, minimal = mlp_explainer.run_explanation(sample = sample, n_classes=n_classes, kmodel=keras_model, model=mp_model, output_bounds=output_bounds, og_bounds=original_bounds, enable_log=False,\n",
    "                                                         )\n",
    "    end = time.perf_counter()\n",
    "    negative_direct_explanations.append(explanation)\n",
    "    times_direct.append(end-start)\n",
    "    sizes_direct.append(len(minimal))\n",
    "    diagonals_direct.append(mymetrics.calculate_hypersolid_diagonal(negative_direct_explanations[-1]))\n",
    "    rsum_direct.append(mymetrics.range_sum(negative_direct_explanations[-1]))\n",
    "    coverage_direct.append(len(mymetrics.calculate_coverage(testing_data, negative_direct_explanations[-1])))\n",
    "    accuracy_direct.append(mymetrics.calculate_accuracy(pred_dataset_df, negative_direct_explanations[-1], 0))\n",
    "    n_feat_ranges_direct.append(mymetrics.get_num_features_with_ranges(negative_direct_explanations[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3c9e3c7-2f23-489c-8932-dd86ee862aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positive_direct_explanations = []\n",
    "for i, sample in enumerate((testing_data.to_numpy()[:, :-1][positive_indexes])):\n",
    "    start = time.perf_counter()\n",
    "    explanation, minimal = mlp_explainer.run_explanation(sample = sample, n_classes=n_classes, kmodel=keras_model, model=mp_model, output_bounds=output_bounds, og_bounds=original_bounds, enable_log=False,\n",
    "                                                         )\n",
    "    end = time.perf_counter()\n",
    "    positive_direct_explanations.append(explanation)\n",
    "    times_direct.append(end-start)\n",
    "    sizes_direct.append(len(minimal))\n",
    "    diagonals_direct.append(mymetrics.calculate_hypersolid_diagonal(positive_direct_explanations[-1]))\n",
    "    rsum_direct.append(mymetrics.range_sum(positive_direct_explanations[-1]))\n",
    "    coverage_direct.append(len(mymetrics.calculate_coverage(testing_data, positive_direct_explanations[-1])))\n",
    "    accuracy_direct.append(mymetrics.calculate_accuracy(pred_dataset_df, positive_direct_explanations[-1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c5f7928-588c-43fd-8dd9-d4085f3c5299",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 0.75\n",
      "Starting Negative\n",
      "End of Negative\n",
      "Starting Positive\n",
      "End of Positive\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Direct_MEAN</th>\n",
       "      <th>Direct_STD</th>\n",
       "      <th>Twostep_MEAN</th>\n",
       "      <th>Twostep_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Time</td>\n",
       "      <td>1.674586</td>\n",
       "      <td>0.503878</td>\n",
       "      <td>3.088299</td>\n",
       "      <td>1.107053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Size</td>\n",
       "      <td>21.532164</td>\n",
       "      <td>3.704409</td>\n",
       "      <td>21.532164</td>\n",
       "      <td>3.704409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diagonal</td>\n",
       "      <td>3.664606</td>\n",
       "      <td>0.31622</td>\n",
       "      <td>3.675802</td>\n",
       "      <td>0.288957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ranges_Sum</td>\n",
       "      <td>16.54589</td>\n",
       "      <td>2.109009</td>\n",
       "      <td>16.69812</td>\n",
       "      <td>1.874391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N_Feature_Ranges</td>\n",
       "      <td>28.733333</td>\n",
       "      <td>3.544323</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coverage</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Metric Direct_MEAN Direct_STD Twostep_MEAN Twostep_STD\n",
       "0              Time    1.674586   0.503878     3.088299    1.107053\n",
       "1              Size   21.532164   3.704409    21.532164    3.704409\n",
       "2          Diagonal    3.664606    0.31622     3.675802    0.288957\n",
       "3        Ranges_Sum    16.54589   2.109009     16.69812    1.874391\n",
       "4  N_Feature_Ranges   28.733333   3.544323         30.0         0.0\n",
       "5          Coverage         1.0        0.0          1.0         0.0\n",
       "6          Accuracy         1.0        0.0          1.0         0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_values = [0.50] #[0.25, 0.50, 0.75]\n",
    "for p_value in p_values:\n",
    "    print(f\"p = {p_value}\")\n",
    "    times_twostep = []\n",
    "    sizes_twostep = []\n",
    "    diagonals_twostep = []\n",
    "    rsum_twostep = []\n",
    "    n_feat_ranges_twostep = []\n",
    "    coverage_twostep = []\n",
    "    accuracy_twostep = []\n",
    "    pos_exp_twostep = []\n",
    "    neg_exp_twostep = []\n",
    "    negative_twostep_explanations = []\n",
    "    print(\"Starting Negative\")\n",
    "    for i, sample in enumerate((testing_data.to_numpy()[:, :-1][negative_indexes])):\n",
    "        start = time.perf_counter()\n",
    "        explanation, minimal = mlp_explainer.run_explanation_doublestep(sample = sample, n_classes=n_classes, kmodel=keras_model, model=mp_model, output_bounds=output_bounds, og_bounds=original_bounds, p=p_value)\n",
    "        end = time.perf_counter()\n",
    "        negative_twostep_explanations.append(explanation)\n",
    "        times_twostep.append(end-start)\n",
    "        sizes_twostep.append(len(minimal))\n",
    "        diagonals_twostep.append(mymetrics.calculate_hypersolid_diagonal(negative_twostep_explanations[-1]))\n",
    "        rsum_twostep.append(mymetrics.range_sum(negative_twostep_explanations[-1]))\n",
    "        coverage_twostep.append(len(mymetrics.calculate_coverage(testing_data, negative_twostep_explanations[-1])))\n",
    "        accuracy_twostep.append(mymetrics.calculate_accuracy(pred_dataset_df, negative_twostep_explanations[-1], 0))\n",
    "        n_feat_ranges_twostep.append(mymetrics.get_num_features_with_ranges(negative_direct_explanations[-1]))\n",
    "\n",
    "    print(\"End of Negative\")\n",
    "    positive_twostep_explanations = []\n",
    "    print(\"Starting Positive\")\n",
    "    for i, sample in enumerate((testing_data.to_numpy()[:, :-1][positive_indexes])):\n",
    "        start = time.perf_counter()\n",
    "        explanation, minimal = mlp_explainer.run_explanation_doublestep(sample = sample, n_classes=n_classes, kmodel=keras_model, model=mp_model, output_bounds=output_bounds, og_bounds=original_bounds, p=p_value, enable_log=False)\n",
    "        end = time.perf_counter()\n",
    "        positive_twostep_explanations.append(explanation)\n",
    "        times_twostep.append(end-start)\n",
    "        sizes_twostep.append(len(minimal))\n",
    "        diagonals_twostep.append(mymetrics.calculate_hypersolid_diagonal(positive_twostep_explanations[-1]))\n",
    "        rsum_twostep.append(mymetrics.range_sum(positive_twostep_explanations[-1]))\n",
    "        coverage_twostep.append(len(mymetrics.calculate_coverage(testing_data, positive_twostep_explanations[-1])))\n",
    "        accuracy_twostep.append(mymetrics.calculate_accuracy(pred_dataset_df, positive_twostep_explanations[-1], 1))\n",
    "        n_feat_ranges_twostep.append(mymetrics.get_num_features_with_ranges(positive_direct_explanations[-1]))\n",
    "\n",
    "    print(\"End of Positive\")\n",
    "    time_mean_twostep = sum(times_twostep)/len(times_twostep)\n",
    "    time_std_twostep = np.std(times_twostep)\n",
    "    sizes_mean_twostep = sum(sizes_twostep)/len(sizes_twostep)\n",
    "    sizes_std_twostep = np.std(sizes_twostep)\n",
    "    diagonals_mean_twostep = sum(diagonals_twostep)/len(diagonals_twostep)\n",
    "    diagonals_std_twostep = np.std(diagonals_twostep)\n",
    "    rsum_mean_twostep = sum(rsum_twostep)/len(rsum_twostep)\n",
    "    rsum_std_twostep = np.std(rsum_twostep)\n",
    "    n_feat_ranges_mean_twostep = sum(n_feat_ranges_twostep)/len(n_feat_ranges_twostep)\n",
    "    n_feat_ranges_std_twostep = np.std(n_feat_ranges_twostep)\n",
    "    coverage_mean_twostep = sum(coverage_twostep)/len(coverage_twostep)\n",
    "    coverage_std_twostep = np.std(coverage_twostep)\n",
    "    accuracy_mean_twostep = sum(accuracy_twostep)/len(accuracy_twostep)\n",
    "    accuracy_std_twostep = np.std(accuracy_twostep)\n",
    "\n",
    "    time_mean_direct = sum(times_direct)/len(times_direct)\n",
    "    time_std_direct = np.std(times_direct)\n",
    "    sizes_mean_direct = sum(sizes_direct)/len(sizes_direct)\n",
    "    sizes_std_direct = np.std(sizes_direct)\n",
    "    diagonals_mean_direct = sum(diagonals_direct)/len(diagonals_direct)\n",
    "    diagonals_std_direct = np.std(diagonals_direct)\n",
    "    rsum_mean_direct = sum(rsum_direct)/len(rsum_direct)\n",
    "    rsum_std_direct = np.std(rsum_direct)\n",
    "    n_feat_ranges_mean_direct = sum(n_feat_ranges_direct)/len(n_feat_ranges_direct)\n",
    "    n_feat_ranges_std_direct = np.std(n_feat_ranges_direct)\n",
    "    coverage_mean_direct = sum(coverage_direct)/len(coverage_direct)\n",
    "    coverage_std_direct = np.std(coverage_direct)\n",
    "    accuracy_mean_direct = sum(accuracy_direct)/len(accuracy_direct)\n",
    "    accuracy_std_direct = np.std(accuracy_direct)\n",
    "\n",
    "    all_metrics_names = ['Metric','Direct_MEAN','Direct_STD','Twostep_MEAN','Twostep_STD']\n",
    "\n",
    "    all_metrics_mean_df  = pd.DataFrame(columns=all_metrics_names)\n",
    "    pattern_row = ['Time',time_mean_direct, time_std_direct, time_mean_twostep,time_std_twostep]\n",
    "    all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "    pattern_row = ['Size', sizes_mean_direct, sizes_std_direct, sizes_mean_twostep,sizes_std_twostep]\n",
    "    all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "\n",
    "    pattern_row = ['Diagonal', diagonals_mean_direct, diagonals_std_direct, diagonals_mean_twostep,diagonals_std_twostep]\n",
    "    all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "\n",
    "    pattern_row = ['Ranges_Sum', rsum_mean_direct, rsum_std_direct, rsum_mean_twostep,rsum_std_twostep]\n",
    "    all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "\n",
    "    pattern_row = ['N_Feature_Ranges', n_feat_ranges_mean_direct, n_feat_ranges_std_direct, n_feat_ranges_mean_twostep,n_feat_ranges_std_twostep]\n",
    "    all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "\n",
    "    pattern_row = ['Coverage', coverage_mean_direct, coverage_std_direct, coverage_mean_twostep,coverage_std_twostep]\n",
    "    all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "    pattern_row = ['Accuracy', accuracy_mean_direct, accuracy_std_direct, accuracy_mean_twostep,accuracy_std_twostep]\n",
    "    all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "    metrics_dataframes.append(all_metrics_mean_df)\n",
    "\n",
    "    display(all_metrics_mean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4541974b-1e9d-4b34-8b3b-17b21e0e64f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dfi.export(all_metrics_mean_df, './saved_dataframe_image/'+dataset_name +\"_\"+ str(p_values[0])+'.jpg')\n",
    "# all_metrics_mean_df.to_csv('./saved_dataframe_csv/'+dataset_name +\"_\"+ str(p_values[0])+'.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
