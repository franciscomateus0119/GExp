{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf8875-8275-43ef-8602-8ac32a8a4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import utility\n",
    "import math\n",
    "from time import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4a03e8-0ad3-4449-a597-e9253c6cd243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_column():\n",
    "    df = pd.read_csv('./datasets/column_2C.dat', sep=\" \", names=['pelvic_incidence', 'pelvic_tilt', 'lumbar_lordosis_angle', 'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis','target'])\n",
    "    df['target']=np.where(df['target']=='AB',1,0)\n",
    "    return df\n",
    "\n",
    "def load_blood_transfusion():\n",
    "    df = pd.read_csv('./datasets/blood_transfusion.csv')\n",
    "    return df\n",
    "\n",
    "def load_ionosphere():\n",
    "    df = pd.read_csv('./datasets/Ionosphere.csv')\n",
    "    return df\n",
    "\n",
    "def load_parkinson():\n",
    "    df = pd.read_csv('./datasets/parkinsons.csv')\n",
    "    return df\n",
    "\n",
    "def load_pima():\n",
    "    df = pd.read_csv('./datasets/diabetes.csv')\n",
    "    df.rename(columns={'Outcome': 'target'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def load_glass():\n",
    "    df = pd.read_csv('./datasets/glass.csv')\n",
    "    # Avoid to_categorical error due to missing class '4'\n",
    "    unique_labels = sorted(df['target'].unique())  # Ensure sorted order\n",
    "    label_map = {original: new for new, original in enumerate(unique_labels)}\n",
    "    \n",
    "    df['target'] = df['target'].map(label_map)\n",
    "    return df\n",
    "\n",
    "def load_climate():\n",
    "    df = pd.read_csv('./datasets/climate_model_simulation_crashes.csv')\n",
    "    return df\n",
    "\n",
    "def load_modeling():\n",
    "    df = pd.read_csv('./datasets/User_Knowledge_Modeling.csv')\n",
    "    unique_labels = sorted(df['target'].unique())  # Ensure sorted order\n",
    "    label_map = {original: new for new, original in enumerate(unique_labels)}\n",
    "    \n",
    "    df['target'] = df['target'].map(label_map)\n",
    "    return df\n",
    "\n",
    "def load_banknote():\n",
    "    df = pd.read_csv('./datasets/banknote_authentication.csv')\n",
    "    return df\n",
    "\n",
    "def load_sonar():\n",
    "    df = pd.read_csv('./datasets/sonar.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137926e-6b5c-4e37-a185-a101c893fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SklearnDatasets\n",
    "df = load_sonar()\n",
    "dir_path = 'Sonar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db1477-624e-4bc3-a60d-e5cd18691935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed7ed34-d421-4450-9ced-24bcb76a4667",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.values[:, :-1])\n",
    "scaled_df = scaler.transform(df.values[:, :-1])\n",
    "lower_bound = scaled_df.min()\n",
    "upper_bound = scaled_df.max()\n",
    "print(lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de19ab4-c9ae-4bc7-b35d-83013b653096",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e28039-c613-40ba-b64f-f898b791b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "#targets = (utility.check_targets_0_1(df.values[:,-1])).astype(np.int32)\n",
    "#df_scaled['target'] = targets\n",
    "targets = df['target'].values\n",
    "df_scaled['target'] = df['target']\n",
    "num_classes = len(df_scaled['target'].unique())\n",
    "display(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce996f-27a0-4b01-8e4e-ead305ffc00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(50)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "n_neurons = X_train.shape[1]\n",
    "n_hidden_layers = 1\n",
    "print(f'n_hidden_layers: {n_hidden_layers}, n_neurons {n_neurons}')\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(X_train.shape[1],)),\n",
    "    layers.Dense(n_neurons, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model_path = f'new_models/{dir_path}.keras'\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=40)\n",
    "ck = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_accuracy', save_best_only=True)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
    "start = time()\n",
    "model.fit(X_train,y_train, epochs=400, batch_size=32,validation_data=(X_test, y_test), verbose=1, callbacks=[ck, es])\n",
    "print(f'Training time: {time()-start}')\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "print('Training Results')\n",
    "model.evaluate(X_train, y_train, verbose=2)\n",
    "print('Test Results')\n",
    "model.evaluate(X_test, y_test, verbose=2)\n",
    "model.save(f'new_models/{dir_path}.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ca14d-1827-438e-a34a-9c268cfd14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  \n",
    "\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_test_classes, y_pred_classes,digits=4)\n",
    "print(report)\n",
    "\n",
    "# Save the report to a text file\n",
    "with open(f'new_models/{dir_path}_report.txt', 'w') as f:\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef3b46-692b-45ca-b5c1-44584a5a63ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
