{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50f05f7-5f70-44e3-a154-d448a34155d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import docplex\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utility\n",
    "import copy\n",
    "import mlp_explainer\n",
    "import mymetrics\n",
    "import time\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from milp import codify_network\n",
    "from teste import get_minimal_explanation\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b77688-1364-4f79-b3b1-9f30f5fba025",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0000000000000002\n",
      "Directory already exists: Climate_results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vconst_corr</th>\n",
       "      <th>vconst_2</th>\n",
       "      <th>vconst_3</th>\n",
       "      <th>vconst_4</th>\n",
       "      <th>vconst_5</th>\n",
       "      <th>vconst_7</th>\n",
       "      <th>ah_corr</th>\n",
       "      <th>ah_bolus</th>\n",
       "      <th>slm_corr</th>\n",
       "      <th>efficiency_factor</th>\n",
       "      <th>tidal_mix_max</th>\n",
       "      <th>vertical_decay_scale</th>\n",
       "      <th>convect_corr</th>\n",
       "      <th>bckgrnd_vdc1</th>\n",
       "      <th>bckgrnd_vdc_ban</th>\n",
       "      <th>bckgrnd_vdc_eq</th>\n",
       "      <th>bckgrnd_vdc_psim</th>\n",
       "      <th>Prandtl</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.859671</td>\n",
       "      <td>0.928788</td>\n",
       "      <td>0.252421</td>\n",
       "      <td>0.298148</td>\n",
       "      <td>0.169988</td>\n",
       "      <td>0.737921</td>\n",
       "      <td>0.426147</td>\n",
       "      <td>0.568669</td>\n",
       "      <td>0.474011</td>\n",
       "      <td>0.244266</td>\n",
       "      <td>0.103856</td>\n",
       "      <td>0.870925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447325</td>\n",
       "      <td>0.307274</td>\n",
       "      <td>0.860540</td>\n",
       "      <td>0.797506</td>\n",
       "      <td>0.870159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.606367</td>\n",
       "      <td>0.457227</td>\n",
       "      <td>0.359316</td>\n",
       "      <td>0.306302</td>\n",
       "      <td>0.844088</td>\n",
       "      <td>0.937501</td>\n",
       "      <td>0.442487</td>\n",
       "      <td>0.829203</td>\n",
       "      <td>0.295175</td>\n",
       "      <td>0.616383</td>\n",
       "      <td>0.975832</td>\n",
       "      <td>0.916335</td>\n",
       "      <td>0.847149</td>\n",
       "      <td>0.863988</td>\n",
       "      <td>0.346527</td>\n",
       "      <td>0.356977</td>\n",
       "      <td>0.438628</td>\n",
       "      <td>0.512305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998404</td>\n",
       "      <td>0.372474</td>\n",
       "      <td>0.517729</td>\n",
       "      <td>0.505192</td>\n",
       "      <td>0.619230</td>\n",
       "      <td>0.607119</td>\n",
       "      <td>0.745857</td>\n",
       "      <td>0.195983</td>\n",
       "      <td>0.817388</td>\n",
       "      <td>0.679023</td>\n",
       "      <td>0.803377</td>\n",
       "      <td>0.645045</td>\n",
       "      <td>0.719860</td>\n",
       "      <td>0.924776</td>\n",
       "      <td>0.315136</td>\n",
       "      <td>0.250661</td>\n",
       "      <td>0.285677</td>\n",
       "      <td>0.365818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.783951</td>\n",
       "      <td>0.102452</td>\n",
       "      <td>0.196926</td>\n",
       "      <td>0.421678</td>\n",
       "      <td>0.742619</td>\n",
       "      <td>0.491993</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.392530</td>\n",
       "      <td>0.006825</td>\n",
       "      <td>0.470614</td>\n",
       "      <td>0.597745</td>\n",
       "      <td>0.763119</td>\n",
       "      <td>0.362815</td>\n",
       "      <td>0.912788</td>\n",
       "      <td>0.978782</td>\n",
       "      <td>0.848106</td>\n",
       "      <td>0.699851</td>\n",
       "      <td>0.476013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406331</td>\n",
       "      <td>0.512871</td>\n",
       "      <td>0.060808</td>\n",
       "      <td>0.636602</td>\n",
       "      <td>0.845558</td>\n",
       "      <td>0.442502</td>\n",
       "      <td>0.188403</td>\n",
       "      <td>0.488124</td>\n",
       "      <td>0.357468</td>\n",
       "      <td>0.550894</td>\n",
       "      <td>0.743812</td>\n",
       "      <td>0.312245</td>\n",
       "      <td>0.651382</td>\n",
       "      <td>0.521167</td>\n",
       "      <td>0.042880</td>\n",
       "      <td>0.377137</td>\n",
       "      <td>0.280134</td>\n",
       "      <td>0.132101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.657524</td>\n",
       "      <td>0.488972</td>\n",
       "      <td>0.132920</td>\n",
       "      <td>0.411748</td>\n",
       "      <td>0.087088</td>\n",
       "      <td>0.357003</td>\n",
       "      <td>0.478322</td>\n",
       "      <td>0.029435</td>\n",
       "      <td>0.399290</td>\n",
       "      <td>0.279224</td>\n",
       "      <td>0.383881</td>\n",
       "      <td>0.887841</td>\n",
       "      <td>0.770091</td>\n",
       "      <td>0.458214</td>\n",
       "      <td>0.334277</td>\n",
       "      <td>0.574193</td>\n",
       "      <td>0.610521</td>\n",
       "      <td>0.737892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0.916598</td>\n",
       "      <td>0.843419</td>\n",
       "      <td>0.519281</td>\n",
       "      <td>0.089032</td>\n",
       "      <td>0.336768</td>\n",
       "      <td>0.896088</td>\n",
       "      <td>0.979657</td>\n",
       "      <td>0.675781</td>\n",
       "      <td>0.261753</td>\n",
       "      <td>0.798072</td>\n",
       "      <td>0.353296</td>\n",
       "      <td>0.043760</td>\n",
       "      <td>0.993356</td>\n",
       "      <td>0.345456</td>\n",
       "      <td>0.512575</td>\n",
       "      <td>0.812605</td>\n",
       "      <td>0.593655</td>\n",
       "      <td>0.142388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>0.478770</td>\n",
       "      <td>0.942190</td>\n",
       "      <td>0.770312</td>\n",
       "      <td>0.952901</td>\n",
       "      <td>0.188910</td>\n",
       "      <td>0.112643</td>\n",
       "      <td>0.745273</td>\n",
       "      <td>0.527745</td>\n",
       "      <td>0.873045</td>\n",
       "      <td>0.191563</td>\n",
       "      <td>0.829540</td>\n",
       "      <td>0.100668</td>\n",
       "      <td>0.549651</td>\n",
       "      <td>0.380490</td>\n",
       "      <td>0.198392</td>\n",
       "      <td>0.869370</td>\n",
       "      <td>0.461834</td>\n",
       "      <td>0.652951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.779788</td>\n",
       "      <td>0.868822</td>\n",
       "      <td>0.705883</td>\n",
       "      <td>0.984308</td>\n",
       "      <td>0.421232</td>\n",
       "      <td>0.710041</td>\n",
       "      <td>0.174764</td>\n",
       "      <td>0.266066</td>\n",
       "      <td>0.761005</td>\n",
       "      <td>0.436503</td>\n",
       "      <td>0.691343</td>\n",
       "      <td>0.826958</td>\n",
       "      <td>0.981812</td>\n",
       "      <td>0.112638</td>\n",
       "      <td>0.365232</td>\n",
       "      <td>0.201434</td>\n",
       "      <td>0.536599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>0.608403</td>\n",
       "      <td>0.029726</td>\n",
       "      <td>0.598830</td>\n",
       "      <td>0.796222</td>\n",
       "      <td>0.145100</td>\n",
       "      <td>0.378970</td>\n",
       "      <td>0.459962</td>\n",
       "      <td>0.425757</td>\n",
       "      <td>0.054496</td>\n",
       "      <td>0.480114</td>\n",
       "      <td>0.307543</td>\n",
       "      <td>0.231253</td>\n",
       "      <td>0.464602</td>\n",
       "      <td>0.582631</td>\n",
       "      <td>0.970163</td>\n",
       "      <td>0.465127</td>\n",
       "      <td>0.760819</td>\n",
       "      <td>0.762640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     vconst_corr  vconst_2  vconst_3  vconst_4  vconst_5  vconst_7   ah_corr  \\\n",
       "0       0.859671  0.928788  0.252421  0.298148  0.169988  0.737921  0.426147   \n",
       "1       0.606367  0.457227  0.359316  0.306302  0.844088  0.937501  0.442487   \n",
       "2       0.998404  0.372474  0.517729  0.505192  0.619230  0.607119  0.745857   \n",
       "3       0.783951  0.102452  0.196926  0.421678  0.742619  0.491993  0.000941   \n",
       "4       0.406331  0.512871  0.060808  0.636602  0.845558  0.442502  0.188403   \n",
       "..           ...       ...       ...       ...       ...       ...       ...   \n",
       "535     0.657524  0.488972  0.132920  0.411748  0.087088  0.357003  0.478322   \n",
       "536     0.916598  0.843419  0.519281  0.089032  0.336768  0.896088  0.979657   \n",
       "537     0.478770  0.942190  0.770312  0.952901  0.188910  0.112643  0.745273   \n",
       "538     0.007388  0.779788  0.868822  0.705883  0.984308  0.421232  0.710041   \n",
       "539     0.608403  0.029726  0.598830  0.796222  0.145100  0.378970  0.459962   \n",
       "\n",
       "     ah_bolus  slm_corr  efficiency_factor  tidal_mix_max  \\\n",
       "0    0.568669  0.474011           0.244266       0.103856   \n",
       "1    0.829203  0.295175           0.616383       0.975832   \n",
       "2    0.195983  0.817388           0.679023       0.803377   \n",
       "3    0.392530  0.006825           0.470614       0.597745   \n",
       "4    0.488124  0.357468           0.550894       0.743812   \n",
       "..        ...       ...                ...            ...   \n",
       "535  0.029435  0.399290           0.279224       0.383881   \n",
       "536  0.675781  0.261753           0.798072       0.353296   \n",
       "537  0.527745  0.873045           0.191563       0.829540   \n",
       "538  0.174764  0.266066           0.761005       0.436503   \n",
       "539  0.425757  0.054496           0.480114       0.307543   \n",
       "\n",
       "     vertical_decay_scale  convect_corr  bckgrnd_vdc1  bckgrnd_vdc_ban  \\\n",
       "0                0.870925      1.000000      0.447325         0.307274   \n",
       "1                0.916335      0.847149      0.863988         0.346527   \n",
       "2                0.645045      0.719860      0.924776         0.315136   \n",
       "3                0.763119      0.362815      0.912788         0.978782   \n",
       "4                0.312245      0.651382      0.521167         0.042880   \n",
       "..                    ...           ...           ...              ...   \n",
       "535              0.887841      0.770091      0.458214         0.334277   \n",
       "536              0.043760      0.993356      0.345456         0.512575   \n",
       "537              0.100668      0.549651      0.380490         0.198392   \n",
       "538              0.691343      0.826958      0.981812         0.112638   \n",
       "539              0.231253      0.464602      0.582631         0.970163   \n",
       "\n",
       "     bckgrnd_vdc_eq  bckgrnd_vdc_psim   Prandtl  target  \n",
       "0          0.860540          0.797506  0.870159       0  \n",
       "1          0.356977          0.438628  0.512305       1  \n",
       "2          0.250661          0.285677  0.365818       1  \n",
       "3          0.848106          0.699851  0.476013       1  \n",
       "4          0.377137          0.280134  0.132101       1  \n",
       "..              ...               ...       ...     ...  \n",
       "535        0.574193          0.610521  0.737892       1  \n",
       "536        0.812605          0.593655  0.142388       0  \n",
       "537        0.869370          0.461834  0.652951       1  \n",
       "538        0.365232          0.201434  0.536599       1  \n",
       "539        0.465127          0.760819  0.762640       1  \n",
       "\n",
       "[540 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_climate():\n",
    "    df = pd.read_csv('./datasets/climate_model_simulation_crashes.csv')\n",
    "    return df\n",
    "#Glass Dataset\n",
    "df = load_climate()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.values[:, :-1])\n",
    "scaled_df = scaler.transform(df.values[:, :-1])\n",
    "lower_bound = scaled_df.min()\n",
    "upper_bound = scaled_df.max()\n",
    "print(lower_bound, upper_bound)\n",
    "df_scaled = pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "#targets = (utility.check_targets_0_1(df.values[:,-1])).astype(np.int32)\n",
    "targets = df['target'].values\n",
    "df_scaled['target'] = targets\n",
    "columns = df_scaled.columns\n",
    "dataset_name = 'Climate'\n",
    "result_path = f'{dataset_name}_results'\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "    print(f\"Created directory: {result_path}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {result_path}\")\n",
    "display(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482f0ed7-ffeb-4f9b-a7d1-4590caa730d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(50)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "X = np.concatenate((X_train,X_test),axis=0)\n",
    "y = np.concatenate((y_train,y_test),axis=0)\n",
    "\n",
    "training_data = pd.DataFrame(X_train, columns = columns[:-1])\n",
    "training_data[columns[-1]] = y_train\n",
    "testing_data = pd.DataFrame(X_test, columns = columns[:-1])\n",
    "testing_data[columns[-1]] = y_test\n",
    "dataframe = pd.concat([training_data, testing_data])\n",
    "data = dataframe.to_numpy()\n",
    "n_classes = dataframe['target'].nunique()\n",
    "\n",
    "original_bounds = [[dataframe[dataframe.columns[i]].min(),dataframe[dataframe.columns[i]].max()] for i in range(len(dataframe.columns[:-1]))]\n",
    "keras_model = tf.keras.models.load_model(f'new_models/{dataset_name}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed248398-dffb-4579-a08e-cba588c0cda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 1.0],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0000000000000002],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0000000000000002],\n",
       " [0.0, 1.0],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 1.0000000000000002]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0271f8c-4ee7-440b-81c8-f6cbb73cbdc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mp_model, output_bounds = codify_network(keras_model, dataframe, 'fischetti', relax_constraints=False)\n",
    "with open(f'{result_path}/{dataset_name}_mp_model.pkl', 'wb') as f:\n",
    "    pickle.dump(mp_model, f)\n",
    "\n",
    "with open(f'bounds/{dataset_name}_output_bounds.pkl', 'wb') as f:\n",
    "    pickle.dump(output_bounds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0fdeab-f0c7-4079-ae50-b90a8262b0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7500    0.0857    0.1538        35\n",
      "         1.0     0.9202    0.9973    0.9572       370\n",
      "\n",
      "    accuracy                         0.9185       405\n",
      "   macro avg     0.8351    0.5415    0.5555       405\n",
      "weighted avg     0.9055    0.9185    0.8878       405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "possible_classes = np.unique(y_test)\n",
    "class_indexes = []\n",
    "class_predictions = []\n",
    "for i in range(n_classes):\n",
    "    class_indexes.append([])\n",
    "    class_predictions.append([])\n",
    "possible_classes, class_indexes, class_predictions\n",
    "data = testing_data.to_numpy()\n",
    "for i in range(len(data)):\n",
    "    predictions.append(mlp_explainer.model_classification_output(k_model=keras_model, net_input=data[i, :-1])[1].numpy())    \n",
    "    for j,p_class in enumerate(possible_classes):\n",
    "        if predictions[-1] == p_class:\n",
    "            class_indexes[j].append(i)\n",
    "            class_predictions[j].append(data[i, :-1])\n",
    "print(\"Metrics:\", classification_report(testing_data.to_numpy()[:, -1], predictions,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c828902-07c9-472f-af54-f1d7bcf8568d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = list(testing_data.columns)\n",
    "if 'target' not in cols:\n",
    "    cols.append('target')\n",
    "predicted_dataset = []\n",
    "for i,pos_class in enumerate(np.unique(y_test)):\n",
    "    for instance in (testing_data.to_numpy()[:, :-1][class_indexes[i]]):\n",
    "        instance = np.append(instance, pos_class.astype('int'))\n",
    "        predicted_dataset.append(instance)\n",
    "predicted_dataset = np.asarray(predicted_dataset)\n",
    "pred_dataset_df = pd.DataFrame(predicted_dataset, columns=cols)\n",
    "pred_dataset_df['target'] = pred_dataset_df['target'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90ccbfce-8f7a-4da1-acb0-c56a29880d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Bounds to CSV\n",
    "np.savez(f'bounds/{dataset_name}_data_bounds.npz', original_bounds=original_bounds)\n",
    "# Save Testing Set to CSV\n",
    "pred_dataset_df.to_csv(f'{dataset_name}_results/{dataset_name}_X_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1887131a-f006-46c8-8f7d-97f869cd7006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_dataframes = []\n",
    "times_onestep = []\n",
    "sizes_onestep = []\n",
    "rsum_onestep = []\n",
    "coverage_onestep = []\n",
    "pos_exp_onestep = []\n",
    "neg_exp_onestep = []\n",
    "onestep_explanations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29d16944-1ca7-4e33-bd38-5b6d8f06fb95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 1.0],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0000000000000002],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0000000000000002],\n",
       " [0.0, 1.0],\n",
       " [0.0, 0.9999999999999999],\n",
       " [0.0, 1.0000000000000002]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c9e3c7-2f23-489c-8932-dd86ee862aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 0.25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>ONESTEP_MEAN</th>\n",
       "      <th>ONESTEP_STD</th>\n",
       "      <th>TWOSTEP_MEAN</th>\n",
       "      <th>TWOSTEP_STD</th>\n",
       "      <th>MEAN_DIFF_%</th>\n",
       "      <th>STD_DIFF_%</th>\n",
       "      <th>POINTWISE_MEAN_%</th>\n",
       "      <th>POINTWISE_STD_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Time</td>\n",
       "      <td>0.534172</td>\n",
       "      <td>0.120262</td>\n",
       "      <td>0.810320</td>\n",
       "      <td>0.180841</td>\n",
       "      <td>51.696378</td>\n",
       "      <td>50.372864</td>\n",
       "      <td>53.017449</td>\n",
       "      <td>24.806957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Size</td>\n",
       "      <td>10.269136</td>\n",
       "      <td>2.753074</td>\n",
       "      <td>10.269136</td>\n",
       "      <td>2.753074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ranges_Sum</td>\n",
       "      <td>12.279118</td>\n",
       "      <td>1.168672</td>\n",
       "      <td>12.307182</td>\n",
       "      <td>1.114568</td>\n",
       "      <td>0.228549</td>\n",
       "      <td>-4.629517</td>\n",
       "      <td>0.371410</td>\n",
       "      <td>4.286480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coverage</td>\n",
       "      <td>1.046914</td>\n",
       "      <td>0.222825</td>\n",
       "      <td>1.049383</td>\n",
       "      <td>0.227777</td>\n",
       "      <td>0.235849</td>\n",
       "      <td>2.222359</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>9.283097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Metric  ONESTEP_MEAN  ONESTEP_STD  TWOSTEP_MEAN  TWOSTEP_STD  \\\n",
       "0        Time      0.534172     0.120262      0.810320     0.180841   \n",
       "1        Size     10.269136     2.753074     10.269136     2.753074   \n",
       "2  Ranges_Sum     12.279118     1.168672     12.307182     1.114568   \n",
       "3    Coverage      1.046914     0.222825      1.049383     0.227777   \n",
       "\n",
       "   MEAN_DIFF_%  STD_DIFF_%  POINTWISE_MEAN_%  POINTWISE_STD_%  \n",
       "0    51.696378   50.372864         53.017449        24.806957  \n",
       "1     0.000000    0.000000          0.000000         0.000000  \n",
       "2     0.228549   -4.629517          0.371410         4.286480  \n",
       "3     0.235849    2.222359          0.493827         9.283097  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_mean_std(arr):\n",
    "    return np.mean(arr), np.std(arr)\n",
    "\n",
    "def relative_percentage_diff(new, old):\n",
    "    if np.any(old == 0):\n",
    "        print(f'Warning: found possible division by zero')\n",
    "        return np.where(old != 0, ((new - old) / old) * 100, np.nan)\n",
    "    return ((new - old) / old) * 100\n",
    "\n",
    "p_value = 0.25\n",
    "print(f\"p = {p_value}\")\n",
    "times_twostep = []\n",
    "sizes_twostep = []\n",
    "rsum_twostep = []\n",
    "coverage_twostep = []\n",
    "twostep_explanations = []\n",
    "for j in range(len(pred_dataset_df['target'].unique())):\n",
    "    for i, sample in enumerate((testing_data.to_numpy()[:, :-1][class_indexes[j]])):\n",
    "        start = time.perf_counter()\n",
    "        \n",
    "        explanation, minimal = mlp_explainer.run_explanation_doublestep(sample = sample, n_classes=n_classes, kmodel=keras_model, model=mp_model, output_bounds=output_bounds, og_bounds=original_bounds, p=p_value)\n",
    "        end = time.perf_counter()\n",
    "        twostep_explanations.append(explanation)\n",
    "        times_twostep.append(end-start)\n",
    "        sizes_twostep.append(len(minimal))\n",
    "        rsum_twostep.append(mymetrics.range_sum(twostep_explanations[-1]))\n",
    "        \n",
    "        coverage_twostep.append(len(mymetrics.calculate_coverage(testing_data, twostep_explanations[-1])))\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        explanation, minimal = mlp_explainer.run_explanation(sample = sample, n_classes=n_classes, kmodel=keras_model, model=mp_model, output_bounds=output_bounds, og_bounds=original_bounds, enable_log=False,\n",
    "                                                             )\n",
    "        end = time.perf_counter()\n",
    "        onestep_explanations.append(explanation)\n",
    "        times_onestep.append(end-start)\n",
    "        sizes_onestep.append(len(minimal))\n",
    "        rsum_onestep.append(mymetrics.range_sum(onestep_explanations[-1]))\n",
    "        coverage_onestep.append(len(mymetrics.calculate_coverage(testing_data, onestep_explanations[-1])))\n",
    "        \n",
    "times_onestep = np.array(times_onestep)\n",
    "times_twostep = np.array(times_twostep)\n",
    "sizes_onestep = np.array(sizes_onestep)\n",
    "sizes_twostep = np.array(sizes_twostep)\n",
    "rsum_onestep = np.array(rsum_onestep)\n",
    "rsum_twostep = np.array(rsum_twostep)\n",
    "coverage_onestep = np.array(coverage_onestep)\n",
    "coverage_twostep = np.array(coverage_twostep)\n",
    "\n",
    "# Compute means and standard deviations\n",
    "(time_mean_onestep, time_std_onestep) = compute_mean_std(times_onestep)\n",
    "(time_mean_twostep, time_std_twostep) = compute_mean_std(times_twostep)\n",
    "\n",
    "(sizes_mean_onestep, sizes_std_onestep) = compute_mean_std(sizes_onestep)\n",
    "(sizes_mean_twostep, sizes_std_twostep) = compute_mean_std(sizes_twostep)\n",
    "\n",
    "(rsum_mean_onestep, rsum_std_onestep) = compute_mean_std(rsum_onestep)\n",
    "(rsum_mean_twostep, rsum_std_twostep) = compute_mean_std(rsum_twostep)\n",
    "\n",
    "(coverage_mean_onestep, coverage_std_onestep) = compute_mean_std(coverage_onestep)\n",
    "(coverage_mean_twostep, coverage_std_twostep) = compute_mean_std(coverage_twostep)\n",
    "\n",
    "# Compute relative percentage differences (Mean & Std)\n",
    "time_mean_diff = relative_percentage_diff(time_mean_twostep, time_mean_onestep)\n",
    "sizes_mean_diff = relative_percentage_diff(sizes_mean_twostep, sizes_mean_onestep)\n",
    "rsum_mean_diff = relative_percentage_diff(rsum_mean_twostep, rsum_mean_onestep)\n",
    "coverage_mean_diff = relative_percentage_diff(coverage_mean_twostep, coverage_mean_onestep)\n",
    "\n",
    "time_std_diff = relative_percentage_diff(time_std_twostep, time_std_onestep)\n",
    "sizes_std_diff = relative_percentage_diff(sizes_std_twostep, sizes_std_onestep)\n",
    "rsum_std_diff = relative_percentage_diff(rsum_std_twostep, rsum_std_onestep)\n",
    "coverage_std_diff = relative_percentage_diff(coverage_std_twostep, coverage_std_onestep)\n",
    "\n",
    "# Compute pointwise relative differences\n",
    "time_relative_pointwise = relative_percentage_diff(times_twostep, times_onestep)\n",
    "sizes_relative_pointwise = relative_percentage_diff(sizes_twostep, sizes_onestep)\n",
    "rsum_relative_pointwise = relative_percentage_diff(rsum_twostep, rsum_onestep)\n",
    "coverage_relative_pointwise = relative_percentage_diff(coverage_twostep, coverage_onestep)\n",
    "\n",
    "# Compute pointwise means\n",
    "time_relative_mean = np.mean(time_relative_pointwise) \n",
    "sizes_relative_mean = np.mean(sizes_relative_pointwise)\n",
    "rsum_relative_mean = np.mean(rsum_relative_pointwise)\n",
    "coverage_relative_mean = np.mean(coverage_relative_pointwise)\n",
    "\n",
    "# Compute pointwise standard deviations\n",
    "time_relative_std = np.std(time_relative_pointwise) \n",
    "sizes_relative_std = np.std(sizes_relative_pointwise)\n",
    "rsum_relative_std = np.std(rsum_relative_pointwise)\n",
    "coverage_relative_std = np.std(coverage_relative_pointwise)\n",
    "\n",
    "# Organize Data\n",
    "all_metrics_data = {\n",
    "    'Metric': ['Time', 'Size', 'Ranges_Sum', 'Coverage'],\n",
    "    'ONESTEP_MEAN': [time_mean_onestep, sizes_mean_onestep, rsum_mean_onestep, coverage_mean_onestep],\n",
    "    'ONESTEP_STD': [time_std_onestep, sizes_std_onestep, rsum_std_onestep, coverage_std_onestep],\n",
    "    'TWOSTEP_MEAN': [time_mean_twostep, sizes_mean_twostep, rsum_mean_twostep, coverage_mean_twostep],\n",
    "    'TWOSTEP_STD': [time_std_twostep, sizes_std_twostep, rsum_std_twostep, coverage_std_twostep],\n",
    "    'MEAN_DIFF_%': [time_mean_diff, sizes_mean_diff, rsum_mean_diff, coverage_mean_diff],\n",
    "    'STD_DIFF_%': [time_std_diff, sizes_std_diff, rsum_std_diff, coverage_std_diff],\n",
    "    'POINTWISE_MEAN_%': [time_relative_mean, sizes_relative_mean, rsum_relative_mean, coverage_relative_mean],\n",
    "    'POINTWISE_STD_%': [time_relative_std, sizes_relative_std, rsum_relative_std, coverage_relative_std]\n",
    "}\n",
    "# Display and save\n",
    "all_metrics_df = pd.DataFrame(all_metrics_data)\n",
    "display(all_metrics_df)\n",
    "all_metrics_df.to_csv(f'{result_path}/results_{p_value}.csv', index=False)\n",
    "\n",
    "#Save Raw Metric Data\n",
    "raw_df = pd.DataFrame({\n",
    "    \"times_onestep\": times_onestep, \n",
    "    \"times_twostep\": times_twostep,\n",
    "    \"sizes_onestep\": sizes_onestep, \n",
    "    \"sizes_twostep\": sizes_twostep,\n",
    "    \"rsum_onestep\": rsum_onestep, \n",
    "    \"rsum_twostep\": rsum_twostep,\n",
    "    \"coverage_onestep\": coverage_onestep, \n",
    "    \"coverage_twostep\": coverage_twostep,\n",
    "    \"time_relative_%\": time_relative_pointwise,\n",
    "    \"sizes_relative_%\": sizes_relative_pointwise,\n",
    "    \"rsum_relative_%\": rsum_relative_pointwise,\n",
    "    \"coverage_relative_%\": coverage_relative_pointwise\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "raw_df.to_csv(f\"{result_path}/raw_metric_data_{p_value}.csv\", index=False)\n",
    "\n",
    "# Save onestep explanations\n",
    "np.savez(f'{result_path}/onestep_explanations_{p_value}.npz', \n",
    "         onestep_explanations=onestep_explanations)\n",
    "\n",
    "# Save twostep explanations\n",
    "np.savez(f'{result_path}/twostep_explanations{p_value}.npz', \n",
    "         twostep_explanations=twostep_explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19beabc1-e595-46e9-a0a8-6e5eed658d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
