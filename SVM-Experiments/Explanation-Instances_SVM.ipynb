{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53035e6d-87d7-47c8-bc06-4d169b7c7909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pulp import *\n",
    "from pulp import LpProblem, LpVariable, LpMinimize, LpInteger, lpSum, value, LpBinary,LpStatusOptimal\n",
    "import pulp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Overwriting previously set objective.\")\n",
    "import utility\n",
    "import docplex.mp.model\n",
    "import docplex\n",
    "import docplex_explainer\n",
    "import mymetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import mymetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ff178-bd21-4a2b-86bd-9a63263c463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = {\n",
    "    'Iris': datasets.load_iris().feature_names,\n",
    "    'Wine': datasets.load_wine().feature_names,\n",
    "    'Breast_Cancer': datasets.load_breast_cancer().feature_names,\n",
    "    'Vertebral-Column': ['pelvic_incidence', 'pelvic_tilt', 'lumbar_lordosis_angle', 'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis'],\n",
    "    'Pima': pd.read_csv('./datasets/diabetes.csv').columns[:-1].values,\n",
    "    'Parkinsons': pd.read_csv('./datasets/parkinsons.csv').columns[:-1].values,\n",
    "    'Blood_Transfusion': pd.read_csv('./datasets/blood_transfusion.csv').columns[:-1].values,\n",
    "    'Ionosphere': pd.read_csv('./datasets/ionosphere.csv').columns[:-1].values,\n",
    "    'Glass': pd.read_csv('./datasets/glass.csv').columns[:-1].values,\n",
    "    'Climate': pd.read_csv('./datasets/climate_model_simulation_crashes.csv').columns[:-1].values,\n",
    "    'Modeling': pd.read_csv('./datasets/User_Knowledge_Modeling.csv').columns[:-1].values,\n",
    "    'Banknote': pd.read_csv('./datasets/banknote_authentication.csv').columns[:-1].values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fcc08c-b55c-4dbf-9e66-b4815409bce7",
   "metadata": {
    "id": "PW90CcDBHbaM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "dataset_name = ['Iris', 'Wine', 'Vertebral-Column', 'Pima', 'Parkinsons', 'Breast_Cancer', 'Blood_Transfusion', 'Ionosphere', 'Glass', 'Climate', 'Modeling', 'Banknote']#, Sonar\n",
    "for dataset in dataset_name:\n",
    "    scaler = joblib.load(f'models/{dataset}_scaler.pkl')\n",
    "    loaded_data = np.load(f'{dataset}_results/pos_explanations_0.25.npz')\n",
    "    onestep_pos = loaded_data['pos_exp_onestep'].round(12)\n",
    "    twostep_pos = loaded_data['pos_exp_twostep'].round(12)\n",
    "    \n",
    "    loaded_data = np.load(f'{dataset}_results/neg_explanations_0.25.npz')\n",
    "    onestep_neg = loaded_data['neg_exp_onestep'].round(12)\n",
    "    twostep_neg = loaded_data['neg_exp_twostep'].round(12)\n",
    "    X_test = pd.read_csv(f'{dataset}_results/{dataset}_X_test_predicted.csv').round(12)\n",
    "    \n",
    "    print(f'\\n\\n#################### {dataset.upper()} ####################')\n",
    "    # Find 1 Onestep smallest explanations\n",
    "    counts = np.sum((onestep_pos[:, :, 0] == 0) & (onestep_pos[:, :, 1] == 1), axis=1)\n",
    "    min_index = np.argsort(counts)[-1:]\n",
    "    onestep_pos = onestep_pos[min_index]\n",
    "\n",
    "    counts = np.sum((onestep_neg[:, :, 0] == 0) & (onestep_neg[:, :, 1] == 1), axis=1)\n",
    "    min_index = np.argsort(counts)[-1:]\n",
    "    onestep_neg = onestep_neg[min_index]\n",
    "\n",
    "    # Find 1 Twostepstep smallest explanations\n",
    "    counts = np.sum((twostep_pos[:, :, 0] == 0) & (twostep_pos[:, :, 1] == 1), axis=1)\n",
    "    min_index = np.argsort(counts)[-1:]\n",
    "    twostep_pos = twostep_pos[min_index]\n",
    "\n",
    "    counts = np.sum((twostep_neg[:, :, 0] == 0) & (twostep_neg[:, :, 1] == 1), axis=1)\n",
    "    min_index = np.argsort(counts)[-1:]\n",
    "    twostep_neg = twostep_neg[min_index]\n",
    "\n",
    "    #Find Positive Instance covered by both Onestep and Twostep\n",
    "    instances_onestep = scaler.inverse_transform(mymetrics.calculate_coverage(X_test,onestep_pos[0]).values[:,:-1])\n",
    "    instances_twostep = scaler.inverse_transform(mymetrics.calculate_coverage(X_test,twostep_pos[0]).values[:,:-1])\n",
    "    instance = np.array([row for row in instances_onestep if any(np.all(row == instances_twostep, axis=1))])[0]\n",
    "    instance_df = pd.DataFrame(data=instance.reshape(1,-1),columns=column_names[dataset])\n",
    "    display(instance_df)\n",
    "\n",
    "    #Onestep\n",
    "    onestep_exp = scaler.inverse_transform(onestep_pos[0].T)\n",
    "    onestep_df = pd.DataFrame(data=onestep_exp,columns=column_names[dataset])\n",
    "    print(f'Onestep_pos - relevant features: {np.where((onestep_pos[0] != [onestep_pos[0].min(), onestep_pos[0].max()]).any(axis=1))}')\n",
    "    display(onestep_df)\n",
    "\n",
    "    #Twostep\n",
    "    twostep_exp = scaler.inverse_transform(twostep_pos[0].T)\n",
    "    twostep_df = pd.DataFrame(data=twostep_exp,columns=column_names[dataset])\n",
    "    print(f'Twostep_pos - relevant features: {np.where((twostep_pos[0] != [twostep_pos[0].min(), twostep_pos[0].max()]).any(axis=1))}')\n",
    "    display(twostep_df)\n",
    "\n",
    "    min_bounds = np.min(onestep_exp, axis=0)  # Minimum values per feature\n",
    "    max_bounds = np.max(onestep_exp, axis=0)  # Maximum values per feature\n",
    "    within_bounds = np.all((instance >= min_bounds) & (instance <= max_bounds))\n",
    "\n",
    "    if within_bounds:\n",
    "        print(f\"Great! {dataset}_instance_pos is within Onestep bounds.\")\n",
    "    else:\n",
    "        print(f\"ERROR {dataset}_instance_pos is OUTSIDE Onestep bounds.\")\n",
    "\n",
    "    min_bounds = np.min(twostep_exp, axis=0)  # Minimum values per feature\n",
    "    max_bounds = np.max(twostep_exp, axis=0)  # Maximum values per feature\n",
    "\n",
    "    within_bounds = np.all((instance >= min_bounds) & (instance <= max_bounds))\n",
    "\n",
    "    if within_bounds:\n",
    "        print(f\"Great! {dataset}_instance_pos is within Twostep bounds.\")\n",
    "    else:\n",
    "        print(f\"ERROR {dataset}_instance_pos is OUTSIDE Twostep bounds.\")\n",
    "    print('----------------------------------------------------------------------------------------------')\n",
    "    print('----------------------------------------------------------------------------------------------')\n",
    "\n",
    "    #Find Negative Instance covered by both Onestep and Twostep\n",
    "    instances_onestep = scaler.inverse_transform(mymetrics.calculate_coverage(X_test,onestep_neg[0]).values[:,:-1])\n",
    "    instances_twostep = scaler.inverse_transform(mymetrics.calculate_coverage(X_test,twostep_neg[0]).values[:,:-1])\n",
    "    instance = np.array([row for row in instances_onestep if any(np.all(row == instances_twostep, axis=1))])[0]\n",
    "    instance_df = pd.DataFrame(data=instance.reshape(1,-1),columns=column_names[dataset])\n",
    "    display(instance_df)\n",
    "\n",
    "    #Onestep\n",
    "    onestep_exp = scaler.inverse_transform(onestep_neg[0].T)\n",
    "    onestep_df = pd.DataFrame(data=onestep_exp,columns=column_names[dataset])\n",
    "    print(f'Onestep_neg - relevant features: {np.where((onestep_neg[0] != [onestep_neg[0].min(), onestep_neg[0].max()]).any(axis=1))}')\n",
    "    display(onestep_df)\n",
    "\n",
    "    #Twostep\n",
    "    twostep_exp = scaler.inverse_transform(twostep_neg[0].T)\n",
    "    twostep_df = pd.DataFrame(data=twostep_exp,columns=column_names[dataset])\n",
    "    print(f'Twostep_neg - relevant features: {np.where((twostep_neg[0] != [twostep_neg[0].min(), twostep_neg[0].max()]).any(axis=1))}')\n",
    "    display(twostep_df)\n",
    "\n",
    "    min_bounds = np.min(onestep_exp, axis=0)  # Minimum values per feature\n",
    "    max_bounds = np.max(onestep_exp, axis=0)  # Maximum values per feature\n",
    "    within_bounds = np.all((instance >= min_bounds) & (instance <= max_bounds))\n",
    "\n",
    "    if within_bounds:\n",
    "        print(f\"Great! {dataset}_instance_neg is within Onestep bounds.\")\n",
    "    else:\n",
    "        print(f\"ERROR {dataset}_instance_neg is OUTSIDE Onestep bounds.\")\n",
    "\n",
    "    min_bounds = np.min(twostep_exp, axis=0)  # Minimum values per feature\n",
    "    max_bounds = np.max(twostep_exp, axis=0)  # Maximum values per feature\n",
    "\n",
    "    within_bounds = np.all((instance >= min_bounds) & (instance <= max_bounds))\n",
    "\n",
    "    if within_bounds:\n",
    "        print(f\"Great! {dataset}_instance_neg is within Twostep bounds.\")\n",
    "    else:\n",
    "        print(f\"ERROR{dataset}_instance_neg is OUTSIDE Twostep bounds.\")\n",
    "    print('----------------------------------------------------------------------------------------------')\n",
    "    print('----------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
