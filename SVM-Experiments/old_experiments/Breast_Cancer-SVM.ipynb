{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53035e6d-87d7-47c8-bc06-4d169b7c7909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pulp import *\n",
    "from pulp import LpProblem, LpVariable, LpMinimize, LpInteger, lpSum, value, LpBinary,LpStatusOptimal\n",
    "import pulp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Overwriting previously set objective.\")\n",
    "import utility\n",
    "import docplex.mp.model\n",
    "import docplex\n",
    "import docplex_explainer\n",
    "import mymetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fcc08c-b55c-4dbf-9e66-b4815409bce7",
   "metadata": {
    "id": "PW90CcDBHbaM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "dataset = datasets.load_breast_cancer()\n",
    "dataset_name = 'Breast_Cancer'\n",
    "df = pd.DataFrame(dataset.data, columns = dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5952206-3fd7-4636-89ec-88e61cfb5702",
   "metadata": {
    "id": "q5plsclR7tUW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(dataset.data)\n",
    "scaled_df = scaler.transform(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa2d6f3-445f-47a7-8d13-dd2891c6bb73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMHNARKC8KJR",
    "outputId": "bbe60b5e-fc61-4253-dfb8-75efb51dfe0a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# Get scaled bounds\n",
    "lower_bound = scaled_df.min()\n",
    "upper_bound = scaled_df.max()\n",
    "print(lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca020aa3-16dc-49f9-acc3-164a3f45dee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Targets:  [0 1] \n",
      "Desired Targets: [-1,1]\n",
      "Is original the desired [-1, 1]?  False\n",
      "1 exists in dataset\n",
      "New dataset targets consists of:  [-1  1]\n"
     ]
    }
   ],
   "source": [
    "# Check if binary targets\n",
    "df_scaled = pd.DataFrame(scaled_df, columns=df.columns)\n",
    "targets = (utility.check_targets(np.where(dataset.target == dataset.target[0],0,1))).astype(np.int32)\n",
    "df_scaled['target'] = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29c6a96-f261-4650-84ec-260b47b2e9e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dx90Sjfwh9cz",
    "outputId": "565c216c-c6e3-48bf-a20b-c64f577ab7f1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Linear: 0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.3,random_state=50,stratify=targets)\n",
    "X = np.concatenate((X_train,X_test),axis=0)\n",
    "y = np.concatenate((y_train,y_test),axis=0)\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "# Train the model using the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy Linear:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98e16f6f-4d86-439e-aab7-50b8de70db0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive patterns = 112,\n",
      "Negative patterns = 59\n"
     ]
    }
   ],
   "source": [
    "# Finding patterns classified as positive/negative\n",
    "positive_indexes,negative_indexes = utility.find_indexes(clf, X_test, threshold=0)\n",
    "print(f\"Positive patterns = {len(positive_indexes)},\\nNegative patterns = {len(negative_indexes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5128478c-c069-4deb-96ae-991e087e4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df.columns)\n",
    "if 'target' not in cols:\n",
    "    cols.append('target')\n",
    "predicted_dataset = []\n",
    "classes = np.array([-1, 1])\n",
    "for instance in (X_test[negative_indexes]):\n",
    "    instance = np.append(instance, classes[0])\n",
    "    predicted_dataset.append(instance)\n",
    "for instance in (X_test[positive_indexes]):\n",
    "    instance = np.append(instance, classes[1])\n",
    "    predicted_dataset.append(instance)\n",
    "predicted_dataset = np.asarray(predicted_dataset)\n",
    "pred_dataset_df = pd.DataFrame(predicted_dataset, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62f42f2-e172-42b0-840b-e5332630f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_names = list(df.columns)\n",
    "if 'target' not in test_df_names:\n",
    "    test_df_names.append('target')\n",
    "test_dataset = []\n",
    "for instance, test_class in zip(X_test, y_test.astype('int32')):\n",
    "    instance = np.append(instance, test_class)\n",
    "    test_dataset.append(instance)\n",
    "test_dataset = np.asarray(test_dataset)\n",
    "test_dataset_df = pd.DataFrame(test_dataset, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31f75d41-dbcb-4786-8f57-0308a162910b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>ONESTEP_MEAN</th>\n",
       "      <th>ONESTEP_STD</th>\n",
       "      <th>TWOSTEP_MEAN</th>\n",
       "      <th>TWOSTEP_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Time</td>\n",
       "      <td>0.114574</td>\n",
       "      <td>0.013015</td>\n",
       "      <td>0.173834</td>\n",
       "      <td>0.020098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Size</td>\n",
       "      <td>21.923977</td>\n",
       "      <td>3.305154</td>\n",
       "      <td>21.923977</td>\n",
       "      <td>3.305154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ranges_Sum</td>\n",
       "      <td>15.729906</td>\n",
       "      <td>3.350432</td>\n",
       "      <td>15.736809</td>\n",
       "      <td>3.349396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coverage</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Metric ONESTEP_MEAN ONESTEP_STD TWOSTEP_MEAN TWOSTEP_STD\n",
       "0        Time     0.114574    0.013015     0.173834    0.020098\n",
       "1        Size    21.923977    3.305154    21.923977    3.305154\n",
       "2  Ranges_Sum    15.729906    3.350432    15.736809    3.349396\n",
       "3    Coverage          1.0         0.0          1.0         0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameter p value\n",
    "p = 0.75\n",
    "\n",
    "#Variables for results\n",
    "times_twostep = []\n",
    "rsum_twostep = []\n",
    "coverage_twostep = []\n",
    "pos_exp_twostep = []\n",
    "neg_exp_twostep = []\n",
    "\n",
    "times_onestep = []\n",
    "rsum_onestep = []\n",
    "coverage_onestep = []\n",
    "pos_exp_onestep = []\n",
    "neg_exp_onestep = []\n",
    "\n",
    "\n",
    "#Generate Explanations for the patterns classfied as negative\n",
    "for idx in  negative_indexes:\n",
    "    \n",
    "    #Twostep\n",
    "    start = time.perf_counter()\n",
    "    exp_ = docplex_explainer.twostep(\n",
    "            classifier = clf,\n",
    "            dual_coef = clf.dual_coef_,\n",
    "            support_vectors = clf.support_vectors_,\n",
    "            intercept = clf.intercept_,\n",
    "            lower_bound = lower_bound,\n",
    "            upper_bound = upper_bound,\n",
    "            data = (X_test[idx]),\n",
    "            p = p,\n",
    "            positive = False)\n",
    "    end = time.perf_counter()\n",
    "    times_twostep.append((end - start))\n",
    "    neg_exp_twostep.append(exp_)\n",
    "    rsum_twostep.append(mymetrics.range_sum(exp_))\n",
    "    coverage_twostep.append(len(mymetrics.calculate_coverage(test_dataset_df, exp_)))\n",
    "    \n",
    "    #Onestep\n",
    "    start = time.perf_counter()\n",
    "    exp = docplex_explainer.onestep(\n",
    "            classifier = clf,\n",
    "            dual_coef = clf.dual_coef_,\n",
    "            support_vectors = clf.support_vectors_,\n",
    "            intercept = clf.intercept_,\n",
    "            lower_bound = lower_bound,\n",
    "            upper_bound = upper_bound,\n",
    "            data = (X_test[idx]),\n",
    "            positive = False)\n",
    "    end = time.perf_counter()\n",
    "    times_onestep.append((end - start))\n",
    "    neg_exp_onestep.append(exp)\n",
    "    rsum_onestep.append(mymetrics.range_sum(exp))\n",
    "    coverage_onestep.append(len(mymetrics.calculate_coverage(test_dataset_df, exp)))\n",
    "\n",
    "#Generate Explanations for the patterns classfied as positive\n",
    "for idx in positive_indexes:\n",
    "    \n",
    "    #Twostep\n",
    "    start = time.perf_counter()\n",
    "    exp_ = docplex_explainer.twostep(\n",
    "            classifier = clf,\n",
    "            dual_coef = clf.dual_coef_,\n",
    "            support_vectors = clf.support_vectors_,\n",
    "            intercept = clf.intercept_,\n",
    "            lower_bound = lower_bound,\n",
    "            upper_bound = upper_bound,\n",
    "            data = (X_test[idx]),\n",
    "            p = p,\n",
    "            positive = True)\n",
    "    end = time.perf_counter()\n",
    "    times_twostep.append((end - start))\n",
    "    pos_exp_twostep.append(exp_)\n",
    "    rsum_twostep.append(mymetrics.range_sum(exp_))\n",
    "    coverage_twostep.append(len(mymetrics.calculate_coverage(test_dataset_df, exp_)))\n",
    "    \n",
    "    #Onestep\n",
    "    start = time.perf_counter()\n",
    "    exp = docplex_explainer.onestep(\n",
    "            classifier = clf,\n",
    "            dual_coef = clf.dual_coef_,\n",
    "            support_vectors = clf.support_vectors_,\n",
    "            intercept = clf.intercept_,\n",
    "            lower_bound = lower_bound,\n",
    "            upper_bound = upper_bound,\n",
    "            data = (X_test[idx]),\n",
    "            positive = True)\n",
    "    end = time.perf_counter()\n",
    "    times_onestep.append((end - start))\n",
    "    pos_exp_onestep.append(exp)\n",
    "    rsum_onestep.append(mymetrics.range_sum(exp))\n",
    "    coverage_onestep.append(len(mymetrics.calculate_coverage(test_dataset_df, exp)))\n",
    "\n",
    "#Check number of expanded features ranges (Twostep)\n",
    "frequency = utility.detail_exp(explanations = neg_exp_twostep, patterns = X_test[negative_indexes],\n",
    "                               number_of_features = len(X_test[0]), show_explanation = False,\n",
    "                               show_frequency = False, low_val = lower_bound, upp_val = upper_bound)\n",
    "\n",
    "neg_sizes_twostep = [len(np.where(x == 1)[0]) for x in frequency.to_numpy()]\n",
    "frequency = utility.detail_exp(explanations = pos_exp_twostep, patterns = X_test[positive_indexes],\n",
    "                               number_of_features = len(X_test[0]), show_explanation = False,\n",
    "                               show_frequency = False, low_val = lower_bound, upp_val = upper_bound)\n",
    "pos_sizes_twostep = [len(np.where(x == 1)[0]) for x in frequency.to_numpy()]\n",
    "feature_sizes_twostep = neg_sizes_twostep.copy()\n",
    "for size in pos_sizes_twostep:\n",
    "    feature_sizes_twostep.append(size)\n",
    "feature_sizes_twostep = np.asarray(feature_sizes_twostep)\n",
    "\n",
    "#Check number of expanded features ranges (Onestep)\n",
    "frequency = utility.detail_exp(explanations = neg_exp_onestep, patterns = X_test[negative_indexes],\n",
    "                               number_of_features = len(X_test[0]), show_explanation = False,\n",
    "                               show_frequency = False, low_val = lower_bound, upp_val = upper_bound)\n",
    "neg_sizes_onestep = [len(np.where(x == 1)[0]) for x in frequency.to_numpy()]\n",
    "\n",
    "frequency = utility.detail_exp(explanations = pos_exp_onestep, patterns = X_test[positive_indexes],\n",
    "                               number_of_features = len(X_test[0]), show_explanation = False,\n",
    "                               show_frequency = False, low_val = lower_bound, upp_val = upper_bound)\n",
    "pos_sizes_onestep = [len(np.where(x == 1)[0]) for x in frequency.to_numpy()]\n",
    "\n",
    "feature_sizes_onestep = neg_sizes_onestep.copy()\n",
    "for size in pos_sizes_onestep:\n",
    "    feature_sizes_onestep.append(size)\n",
    "feature_sizes_onestep = np.asarray(feature_sizes_onestep)\n",
    "\n",
    "#Calculate mean and standard deviation\n",
    "time_mean_twostep = sum(times_twostep)/len(times_twostep)\n",
    "time_std_twostep = np.std(times_twostep)\n",
    "sizes_mean_twostep = sum(feature_sizes_twostep)/len(feature_sizes_twostep)\n",
    "sizes_std_twostep = np.std(feature_sizes_twostep)\n",
    "rsum_mean_twostep = sum(rsum_twostep)/len(rsum_twostep)\n",
    "rsum_std_twostep = np.std(rsum_twostep)\n",
    "coverage_mean_twostep = sum(coverage_twostep)/len(coverage_twostep)\n",
    "coverage_std_twostep = np.std(coverage_twostep)\n",
    "\n",
    "time_mean_onestep = sum(times_onestep)/len(times_onestep)\n",
    "time_std_onestep = np.std(times_onestep)\n",
    "sizes_mean_onestep = sum(feature_sizes_onestep)/len(feature_sizes_onestep)\n",
    "sizes_std_onestep = np.std(feature_sizes_onestep)\n",
    "rsum_mean_onestep = sum(rsum_onestep)/len(rsum_onestep)\n",
    "rsum_std_onestep = np.std(rsum_onestep)\n",
    "coverage_mean_onestep = sum(coverage_onestep)/len(coverage_onestep)\n",
    "coverage_std_onestep = np.std(coverage_onestep)\n",
    "\n",
    "#Make a dataframe with the results.\n",
    "all_metrics_names = ['Metric','ONESTEP_MEAN','ONESTEP_STD','TWOSTEP_MEAN','TWOSTEP_STD']\n",
    "\n",
    "all_metrics_mean_df  = pd.DataFrame(columns=all_metrics_names)\n",
    "pattern_row = ['Time',time_mean_onestep, time_std_onestep, time_mean_twostep,time_std_twostep]\n",
    "all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "pattern_row = ['Size', sizes_mean_onestep, sizes_std_onestep, sizes_mean_twostep,sizes_std_twostep]\n",
    "all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "\n",
    "pattern_row = ['Ranges_Sum', rsum_mean_onestep, rsum_std_onestep, rsum_mean_twostep,rsum_std_twostep]\n",
    "all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "\n",
    "pattern_row = ['Coverage', coverage_mean_onestep, coverage_std_onestep, coverage_mean_twostep,coverage_std_twostep]\n",
    "all_metrics_mean_df.loc[len(all_metrics_mean_df), :] = pattern_row\n",
    "\n",
    "display(all_metrics_mean_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
