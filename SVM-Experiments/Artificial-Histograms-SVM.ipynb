{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53035e6d-87d7-47c8-bc06-4d169b7c7909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pulp import *\n",
    "from pulp import LpProblem, LpVariable, LpMinimize, LpInteger, lpSum, value, LpBinary,LpStatusOptimal\n",
    "import pulp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Overwriting previously set objective.\")\n",
    "import utility\n",
    "import docplex.mp.model\n",
    "import docplex\n",
    "import docplex_explainer\n",
    "import mymetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fcc08c-b55c-4dbf-9e66-b4815409bce7",
   "metadata": {
    "id": "PW90CcDBHbaM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "dataset_name = 'Sonar' #Iris, Wine, Vertebral-Column, Pima, Parkinsons, Breast_Cancer, Blood_Transfusion, Ionosphere, Glass, Climate, Modeling, Banknote, Sonar\n",
    "#df_artificial = pd.read_csv('datasets/artificial/'+f'{dataset_name}_artificial.csv')\n",
    "clf = joblib.load(f'models/{dataset_name}_svm_model.pkl')\n",
    "loaded_bounds = np.load(f'models/{dataset_name}_data_bounds.npz')\n",
    "lower_bound = loaded_bounds['lower_bound']\n",
    "upper_bound = loaded_bounds['upper_bound']\n",
    "np.random.seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc903dd1-fbb5-4cfa-a0c3-4810744b42db",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.0000000001\n",
    "p = 0.25\n",
    "num_instances=1000\n",
    "X_test = pd.read_csv(f'{dataset_name}_results/{dataset_name}_X_test.csv')\n",
    "onestep_coverages = []\n",
    "twostep_coverages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68788c-b895-4bde-9ff4-ca09c26de101",
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in X_test.values:\n",
    "    #print(instance)\n",
    "    artificial_lower_bounds = instance-d\n",
    "    artificial_lower_bounds[artificial_lower_bounds<lower_bound] = lower_bound\n",
    "    artificial_upper_bounds = instance+d\n",
    "    artificial_upper_bounds[artificial_upper_bounds>upper_bound] = upper_bound\n",
    "    #print(artificial_lower_bounds,artificial_upper_bounds)\n",
    "    \n",
    "    \n",
    "    data = np.random.uniform(low=artificial_lower_bounds, high=artificial_upper_bounds, size=(num_instances, len(instance)))\n",
    "    df_artificial = pd.DataFrame(data, columns=X_test.columns)\n",
    "    df_artificial.loc[len(df_artificial)] = instance #Add original instance to the artificial set\n",
    "    X_test_art = df_artificial.values\n",
    "    test_dataset_df = df_artificial\n",
    "        \n",
    "    # Finding patterns classified as positive/negative\n",
    "    positive_indexes,negative_indexes = utility.find_indexes(clf, instance.reshape(1, -1), threshold=0)\n",
    "    \n",
    "    #Variables for results\n",
    "    #coverage_twostep = []\n",
    "    pos_exp_twostep = []\n",
    "    neg_exp_twostep = []\n",
    "    \n",
    "    #coverage_onestep = []\n",
    "    pos_exp_onestep = []\n",
    "    neg_exp_onestep = []\n",
    "    #Generate Explanations for the patterns classified as negative\n",
    "    for idx in  negative_indexes:  \n",
    "        #Onestep\n",
    "        exp = docplex_explainer.onestep(\n",
    "                classifier = clf,\n",
    "                dual_coef = clf.dual_coef_,\n",
    "                support_vectors = clf.support_vectors_,\n",
    "                intercept = clf.intercept_,\n",
    "                lower_bound = lower_bound,\n",
    "                upper_bound = upper_bound,\n",
    "                data = (instance.reshape(1, -1)),\n",
    "                positive = False)\n",
    "        neg_exp_onestep.append(exp)\n",
    "        onestep_coverages.append(len(mymetrics.calculate_coverage(test_dataset_df, exp)))\n",
    "    \n",
    "    #Generate Explanations for the patterns classfied as positive\n",
    "    for idx in positive_indexes:\n",
    "        #Onestep\n",
    "        exp = docplex_explainer.onestep(\n",
    "                classifier = clf,\n",
    "                dual_coef = clf.dual_coef_,\n",
    "                support_vectors = clf.support_vectors_,\n",
    "                intercept = clf.intercept_,\n",
    "                lower_bound = lower_bound,\n",
    "                upper_bound = upper_bound,\n",
    "                data = (instance.reshape(1, -1)),\n",
    "                positive = True)\n",
    "        pos_exp_onestep.append(exp)\n",
    "        #coverage_onestep.append(len(mymetrics.calculate_coverage(test_dataset_df, exp)))\n",
    "        onestep_coverages.append(len(mymetrics.calculate_coverage(test_dataset_df, exp)))\n",
    "    #Generate Explanations for the patterns classified as negative\n",
    "    for idx in  negative_indexes:\n",
    "        \n",
    "        #Twostep\n",
    "        exp_ = docplex_explainer.twostep(\n",
    "                classifier = clf,\n",
    "                dual_coef = clf.dual_coef_,\n",
    "                support_vectors = clf.support_vectors_,\n",
    "                intercept = clf.intercept_,\n",
    "                lower_bound = lower_bound,\n",
    "                upper_bound = upper_bound,\n",
    "                data = (instance.reshape(1, -1)),\n",
    "                p = p,\n",
    "                positive = False)\n",
    "        neg_exp_twostep.append(exp_)\n",
    "        #coverage_twostep.append(len(mymetrics.calculate_coverage(test_dataset_df, exp_)))\n",
    "        twostep_coverages.append(len(mymetrics.calculate_coverage(test_dataset_df, exp_)))\n",
    "    \n",
    "    #Generate Explanations for the patterns classfied as positive\n",
    "    for idx in positive_indexes:\n",
    "        #Twostep\n",
    "        exp_ = docplex_explainer.twostep(\n",
    "                classifier = clf,\n",
    "                dual_coef = clf.dual_coef_,\n",
    "                support_vectors = clf.support_vectors_,\n",
    "                intercept = clf.intercept_,\n",
    "                lower_bound = lower_bound,\n",
    "                upper_bound = upper_bound,\n",
    "                data = (instance.reshape(1, -1)),\n",
    "                p = p,\n",
    "                positive = True)\n",
    "        pos_exp_twostep.append(exp_)\n",
    "        #coverage_twostep.append(len(mymetrics.calculate_coverage(test_dataset_df, exp_)))\n",
    "        twostep_coverages.append(len(mymetrics.calculate_coverage(test_dataset_df, exp_)))\n",
    "        \n",
    "    \n",
    "# Compute means and standard deviations\n",
    "def compute_mean_std(arr):\n",
    "    return np.mean(arr), np.std(arr)\n",
    "\n",
    "# Compute relative percentage differences\n",
    "def relative_percentage_diff(new, old):\n",
    "    if np.any(old == 0):\n",
    "        print(f'Warning: found possible division by zero')\n",
    "        return np.where(old != 0, ((new - old) / old) * 100, np.nan)\n",
    "    return ((new - old) / old) * 100\n",
    "\n",
    "# Ensure all lists are NumPy arrays\n",
    "onestep_coverages = np.array(onestep_coverages)\n",
    "twostep_coverages = np.array(twostep_coverages)\n",
    "\n",
    "\n",
    "(coverage_mean_onestep, coverage_std_onestep) = compute_mean_std(onestep_coverages)\n",
    "(coverage_mean_twostep, coverage_std_twostep) = compute_mean_std(twostep_coverages)\n",
    "\n",
    "\n",
    "coverage_mean_diff = relative_percentage_diff(coverage_mean_twostep, coverage_mean_onestep)\n",
    "coverage_std_diff = relative_percentage_diff(coverage_std_twostep, coverage_std_onestep)\n",
    "coverage_relative_pointwise = relative_percentage_diff(twostep_coverages, onestep_coverages)\n",
    "coverage_relative_mean = np.mean(coverage_relative_pointwise)\n",
    "coverage_relative_std = np.std(coverage_relative_pointwise)\n",
    "    \n",
    "# Organize Data\n",
    "all_metrics_data = {\n",
    "    'Metric': ['Coverage'],\n",
    "    'ONESTEP_MEAN': [coverage_mean_onestep],\n",
    "    'ONESTEP_STD': [coverage_std_onestep],\n",
    "    'TWOSTEP_MEAN': [coverage_mean_twostep],\n",
    "    'TWOSTEP_STD': [coverage_std_twostep],\n",
    "    'MEAN_DIFF_%': [coverage_mean_diff],\n",
    "    'STD_DIFF_%': [coverage_std_diff],\n",
    "    'POINTWISE_MEAN_%': [coverage_relative_mean],\n",
    "    'POINTWISE_STD_%': [coverage_relative_std]\n",
    "}\n",
    "# Display and save\n",
    "all_metrics_df = pd.DataFrame(all_metrics_data)\n",
    "display(all_metrics_df)\n",
    "#all_metrics_df.to_csv(f'{dataset_name}_results/coverage_results_artificial_{p}.csv', index=False)\n",
    "\n",
    "#Save Raw Metric Data\n",
    "raw_df = pd.DataFrame({\n",
    "    \"coverage_onestep\": onestep_coverages, \n",
    "    \"coverage_twostep\": twostep_coverages,\n",
    "    \"coverage_relative_%\": coverage_relative_pointwise\n",
    "})\n",
    "\n",
    "display(raw_df)\n",
    "#raw_df.to_csv(f\"{dataset_name}_results/coverage_raw_metric_data_{p}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9dae55-dc7b-4a70-9c09-dec1c012d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.min(), raw_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51686744-e7cc-4d32-9a0d-9343d6f9d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute relative proportion\n",
    "relative_proportion = np.where(\n",
    "    raw_df['coverage_onestep'] != 0,\n",
    "    ((raw_df['coverage_twostep'] - raw_df['coverage_onestep']) / raw_df['coverage_onestep']) * 100,\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Separate values\n",
    "values_lt_0 = relative_proportion[relative_proportion < 0]\n",
    "values_eq_0 = relative_proportion[relative_proportion == 0]\n",
    "values_gt_0 = relative_proportion[relative_proportion > 0]\n",
    "\n",
    "# Define bin width and edges\n",
    "bin_width = 100\n",
    "min_value = -bin_width if np.nanmin(relative_proportion) >= -bin_width else np.ceil(np.nanmin(relative_proportion) / -bin_width) * -bin_width\n",
    "max_value = np.nanmax(relative_proportion) + bin_width\n",
    "\n",
    "bin_edges_lt_0 = np.arange(min_value, bin_width+1, bin_width)  # Bins for < 0 values\n",
    "bin_edges_gt_0 = np.arange(0, max_value+1+bin_width, bin_width)  # Bins for > 0 values\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot histograms separately\n",
    "ax_list = []\n",
    "if len(values_lt_0) > 0:\n",
    "    ax_lt_0 = sns.histplot(values_lt_0, bins=bin_edges_lt_0, kde=False, color='red', alpha=0.6, label=r'$ < 0$')\n",
    "    ax_list.append(ax_lt_0)\n",
    "\n",
    "if len(values_eq_0) > len(values_gt_0[values_gt_0<bin_width]):    \n",
    "    ax_eq_0 = sns.histplot(values_eq_0, bins=bin_edges_gt_0, kde=False, color='gray', alpha=0.6, label=r'$ = 0$')\n",
    "    ax_list.append(ax_eq_0)\n",
    "\n",
    "if len(values_gt_0) > 0:\n",
    "    ax_gt_0 = sns.histplot(values_gt_0, bins=bin_edges_gt_0, kde=False, color='green', alpha=0.6, label=r'$ > 0$')\n",
    "    ax_list.append(ax_gt_0)\n",
    "\n",
    "\n",
    "if len(values_eq_0) <= len(values_gt_0[values_gt_0<bin_width]):\n",
    "    ax_eq_0 = sns.histplot(values_eq_0, bins=bin_edges_gt_0, kde=False, color='gray', alpha=1, label=r'$ = 0$')\n",
    "    ax_list.append(ax_eq_0)\n",
    "\n",
    "# Add numbers above each bin\n",
    "for ax in ax_list:\n",
    "    for patch in ax.patches:\n",
    "        height = patch.get_height()\n",
    "        if height > 0:\n",
    "            plt.text(\n",
    "                patch.get_x() + patch.get_width() / 2,  # Centered in bin\n",
    "                height,  # Position above the bar\n",
    "                f'{int(height)}',  # Rounded count\n",
    "                ha='center', va='bottom', fontsize=14\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "# Adjust xticks\n",
    "xticks = np.arange(min_value, max_value+1+bin_width, bin_width)\n",
    "plt.xticks(xticks, rotation=80,fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Find the y-position of the highest bar\n",
    "max_height = max([patch.get_height() for patch in plt.gca().patches])\n",
    "\n",
    "ax = plt.gca()  # Get current axis\n",
    "ax.axvline(relative_proportion.min(), color='black', linestyle='--', label=f'Min: {relative_proportion.min():.2f}')\n",
    "ax.axvline(relative_proportion.max(), color='black', linestyle='--', label=f'Max: {relative_proportion.max():.2f}')\n",
    "\n",
    "\n",
    "\n",
    "# Labels and title\n",
    "plt.ylabel('Count',fontsize=14)\n",
    "plt.xlabel('Coverage improvement (%)',fontsize=14)\n",
    "#plt.title(f'{dataset_title_name} - Elementwise coverage (%) comparison Twostep vs Onestep (n={len(raw_df)}, p={p})',fontsize=14)\n",
    "\n",
    "# Correct legend\n",
    "min_line = mlines.Line2D([], [], color='black', linestyle='--', label=f'Min: {relative_proportion.min():.2f}%')\n",
    "max_line = mlines.Line2D([], [], color='black', linestyle='--', label=f'Max: {relative_proportion.max():.2f}%')\n",
    "\n",
    "# Define existing legend handles\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], color='red', lw=4, label=rf'$ < 0$ ({len(values_lt_0)})'),\n",
    "    plt.Line2D([0], [0], color='gray', lw=4, label=rf'$ = 0$ ({len(values_eq_0)})'),\n",
    "    plt.Line2D([0], [0], color='green', lw=4, label=rf'$ > 0$ ({len(values_gt_0)})'),\n",
    "    min_line,  # Add min line\n",
    "    max_line   # Add max line\n",
    "]\n",
    "\n",
    "# Update the legend\n",
    "plt.legend(handles=legend_handles, loc='upper right',fontsize=14)\n",
    "\n",
    "\n",
    "#plt.savefig(f\"{dataset_name}_results/{dataset_name}_artificial_coverage_{p}.eps\", format='eps', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(f\"relative_coverage/{dataset_name}_artificial_coverage_{p}.png\", format='png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f8b41c-4bd1-42d3-9001-337c10b99c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Compute relative proportion\n",
    "# relative_proportion = np.where(\n",
    "#     raw_df['coverage_onestep'] != 0,\n",
    "#     ((raw_df['coverage_twostep'] - raw_df['coverage_onestep']) / raw_df['coverage_onestep']) * 100,\n",
    "#     np.nan\n",
    "# )\n",
    "\n",
    "# # Calculate the min and max values of the cleaned data\n",
    "# min_value = np.nanmin(relative_proportion)\n",
    "# max_value = np.nanmax(relative_proportion)\n",
    "\n",
    "# # Create figure\n",
    "# plt.figure(figsize=(24, 12))\n",
    "\n",
    "# # Plot KDE curve using the entire relative_proportion array\n",
    "# sns.kdeplot(relative_proportion, fill=True, color='blue', alpha=0.5, label='KDE of relative proportion', bw_adjust=0.2)\n",
    "\n",
    "# # Add vertical lines for min and max values\n",
    "# plt.axvline(x=min_value, color='black', linestyle='--', label=f'Min value: {min_value:.3f}')\n",
    "# plt.axvline(x=max_value, color='black', linestyle='--', label=f'Max value: {max_value:.3f}')\n",
    "\n",
    "# # Generate x-ticks at intervals of 100\n",
    "# xticks = np.arange(np.floor(min_value / 100) * 100, np.ceil(max_value / 100) * 100 + 100, 100)\n",
    "# plt.xticks(xticks, rotation=75)  # Rotate for better readability if needed\n",
    "\n",
    "# # Labels and title\n",
    "# plt.ylabel('Density')\n",
    "# plt.xlabel('Coverage (%)')\n",
    "# plt.title(f'{dataset_name} Artificial - Elementwise coverage (%) comparison Twostep vs Onestep (n={len(X_test)}, p={p}, d = {d})', fontsize=16)\n",
    "\n",
    "# # Correct legend\n",
    "# plt.legend()\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615df4a-62e8-4b9e-adcd-efb720c732ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative_proportion.min(),relative_proportion.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d6af76-675e-41b4-8b64-0070418fd8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
