{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53035e6d-87d7-47c8-bc06-4d169b7c7909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pulp import *\n",
    "from pulp import LpProblem, LpVariable, LpMinimize, LpInteger, lpSum, value, LpBinary,LpStatusOptimal\n",
    "import pulp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Overwriting previously set objective.\")\n",
    "import utility\n",
    "import docplex.mp.model\n",
    "import docplex\n",
    "import docplex_explainer\n",
    "import mymetrics\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fcc08c-b55c-4dbf-9e66-b4815409bce7",
   "metadata": {
    "id": "PW90CcDBHbaM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "dataset_name = 'Sonar'\n",
    "df = pd.read_csv('./datasets/sonar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5952206-3fd7-4636-89ec-88e61cfb5702",
   "metadata": {
    "id": "q5plsclR7tUW",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/Sonar_scaler.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.values[:, :-1])\n",
    "scaled_df = scaler.transform(df.values[:, :-1])\n",
    "joblib.dump(scaler, f'models/{dataset_name}_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa2d6f3-445f-47a7-8d13-dd2891c6bb73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMHNARKC8KJR",
    "outputId": "bbe60b5e-fc61-4253-dfb8-75efb51dfe0a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# Get scaled bounds\n",
    "lower_bound = scaled_df.min()\n",
    "upper_bound = scaled_df.max()\n",
    "np.savez(f'models/{dataset_name}_data_bounds.npz', lower_bound=lower_bound, upper_bound=upper_bound)\n",
    "\n",
    "print(lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca020aa3-16dc-49f9-acc3-164a3f45dee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Targets:  [0. 1.] \n",
      "Desired Targets: [0,1]\n",
      "Is original the desired [0, 1]?  True\n"
     ]
    }
   ],
   "source": [
    "# Check if binary targets\n",
    "df_scaled = pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "targets = (utility.check_targets_0_1(df.values[:,-1])).astype(np.int32)\n",
    "df_scaled['target'] = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bafd764c-08bc-4610-ac3a-fd6884bbc8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.136431</td>\n",
       "      <td>0.156451</td>\n",
       "      <td>0.135677</td>\n",
       "      <td>0.035426</td>\n",
       "      <td>0.224956</td>\n",
       "      <td>0.237571</td>\n",
       "      <td>0.407468</td>\n",
       "      <td>0.340904</td>\n",
       "      <td>0.449282</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027104</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>0.435673</td>\n",
       "      <td>0.149660</td>\n",
       "      <td>0.417949</td>\n",
       "      <td>0.502841</td>\n",
       "      <td>0.185355</td>\n",
       "      <td>0.245179</td>\n",
       "      <td>0.060046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.323009</td>\n",
       "      <td>0.221603</td>\n",
       "      <td>0.272011</td>\n",
       "      <td>0.150024</td>\n",
       "      <td>0.283033</td>\n",
       "      <td>0.666756</td>\n",
       "      <td>0.574405</td>\n",
       "      <td>0.755458</td>\n",
       "      <td>0.483045</td>\n",
       "      <td>0.394537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108417</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.199546</td>\n",
       "      <td>0.479487</td>\n",
       "      <td>0.389205</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.140496</td>\n",
       "      <td>0.087760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.182153</td>\n",
       "      <td>0.246892</td>\n",
       "      <td>0.356110</td>\n",
       "      <td>0.243699</td>\n",
       "      <td>0.230028</td>\n",
       "      <td>0.585327</td>\n",
       "      <td>0.648810</td>\n",
       "      <td>0.819405</td>\n",
       "      <td>0.817859</td>\n",
       "      <td>0.869584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319544</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.248538</td>\n",
       "      <td>0.394558</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.889205</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.258953</td>\n",
       "      <td>0.166282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062684</td>\n",
       "      <td>0.070724</td>\n",
       "      <td>0.199737</td>\n",
       "      <td>0.034950</td>\n",
       "      <td>0.034999</td>\n",
       "      <td>0.071486</td>\n",
       "      <td>0.288149</td>\n",
       "      <td>0.269239</td>\n",
       "      <td>0.077447</td>\n",
       "      <td>0.164593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161198</td>\n",
       "      <td>0.080519</td>\n",
       "      <td>0.409357</td>\n",
       "      <td>0.179138</td>\n",
       "      <td>0.176923</td>\n",
       "      <td>0.133523</td>\n",
       "      <td>0.093822</td>\n",
       "      <td>0.107438</td>\n",
       "      <td>0.256351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.550885</td>\n",
       "      <td>0.282898</td>\n",
       "      <td>0.153088</td>\n",
       "      <td>0.079886</td>\n",
       "      <td>0.132640</td>\n",
       "      <td>0.147003</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.531863</td>\n",
       "      <td>0.516659</td>\n",
       "      <td>0.621479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032810</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.235828</td>\n",
       "      <td>0.028205</td>\n",
       "      <td>0.196023</td>\n",
       "      <td>0.102975</td>\n",
       "      <td>0.292011</td>\n",
       "      <td>0.203233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.126844</td>\n",
       "      <td>0.145735</td>\n",
       "      <td>0.050263</td>\n",
       "      <td>0.028293</td>\n",
       "      <td>0.082678</td>\n",
       "      <td>0.410642</td>\n",
       "      <td>0.539773</td>\n",
       "      <td>0.361411</td>\n",
       "      <td>0.333629</td>\n",
       "      <td>0.367653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154066</td>\n",
       "      <td>0.241558</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.248718</td>\n",
       "      <td>0.176136</td>\n",
       "      <td>0.256293</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.348730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.227139</td>\n",
       "      <td>0.040720</td>\n",
       "      <td>0.092970</td>\n",
       "      <td>0.120304</td>\n",
       "      <td>0.175755</td>\n",
       "      <td>0.230046</td>\n",
       "      <td>0.258929</td>\n",
       "      <td>0.212348</td>\n",
       "      <td>0.141419</td>\n",
       "      <td>0.291863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075606</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.365497</td>\n",
       "      <td>0.129252</td>\n",
       "      <td>0.151282</td>\n",
       "      <td>0.088068</td>\n",
       "      <td>0.066362</td>\n",
       "      <td>0.168044</td>\n",
       "      <td>0.140878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.373894</td>\n",
       "      <td>0.184741</td>\n",
       "      <td>0.054205</td>\n",
       "      <td>0.055635</td>\n",
       "      <td>0.072026</td>\n",
       "      <td>0.287288</td>\n",
       "      <td>0.331169</td>\n",
       "      <td>0.247630</td>\n",
       "      <td>0.175181</td>\n",
       "      <td>0.345488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216833</td>\n",
       "      <td>0.062338</td>\n",
       "      <td>0.119883</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>0.389205</td>\n",
       "      <td>0.308924</td>\n",
       "      <td>0.209366</td>\n",
       "      <td>0.057737</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.212389</td>\n",
       "      <td>0.148736</td>\n",
       "      <td>0.156045</td>\n",
       "      <td>0.130766</td>\n",
       "      <td>0.025361</td>\n",
       "      <td>0.336469</td>\n",
       "      <td>0.387446</td>\n",
       "      <td>0.235502</td>\n",
       "      <td>0.276914</td>\n",
       "      <td>0.320463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111270</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.068027</td>\n",
       "      <td>0.079487</td>\n",
       "      <td>0.088068</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.096998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.180678</td>\n",
       "      <td>0.153022</td>\n",
       "      <td>0.039750</td>\n",
       "      <td>0.050880</td>\n",
       "      <td>0.037281</td>\n",
       "      <td>0.063424</td>\n",
       "      <td>0.168290</td>\n",
       "      <td>0.296582</td>\n",
       "      <td>0.261810</td>\n",
       "      <td>0.320463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196862</td>\n",
       "      <td>0.322078</td>\n",
       "      <td>0.108187</td>\n",
       "      <td>0.074830</td>\n",
       "      <td>0.146154</td>\n",
       "      <td>0.105114</td>\n",
       "      <td>0.075515</td>\n",
       "      <td>0.165289</td>\n",
       "      <td>0.251732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f1        f2        f3        f4        f5        f6        f7  \\\n",
       "0    0.136431  0.156451  0.135677  0.035426  0.224956  0.237571  0.407468   \n",
       "1    0.323009  0.221603  0.272011  0.150024  0.283033  0.666756  0.574405   \n",
       "2    0.182153  0.246892  0.356110  0.243699  0.230028  0.585327  0.648810   \n",
       "3    0.062684  0.070724  0.199737  0.034950  0.034999  0.071486  0.288149   \n",
       "4    0.550885  0.282898  0.153088  0.079886  0.132640  0.147003  0.318182   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "203  0.126844  0.145735  0.050263  0.028293  0.082678  0.410642  0.539773   \n",
       "204  0.227139  0.040720  0.092970  0.120304  0.175755  0.230046  0.258929   \n",
       "205  0.373894  0.184741  0.054205  0.055635  0.072026  0.287288  0.331169   \n",
       "206  0.212389  0.148736  0.156045  0.130766  0.025361  0.336469  0.387446   \n",
       "207  0.180678  0.153022  0.039750  0.050880  0.037281  0.063424  0.168290   \n",
       "\n",
       "           f8        f9       f10  ...       f52       f53       f54  \\\n",
       "0    0.340904  0.449282  0.285714  ...  0.027104  0.155844  0.435673   \n",
       "1    0.755458  0.483045  0.394537  ...  0.108417  0.218182  0.111111   \n",
       "2    0.819405  0.817859  0.869584  ...  0.319544  0.418182  0.248538   \n",
       "3    0.269239  0.077447  0.164593  ...  0.161198  0.080519  0.409357   \n",
       "4    0.531863  0.516659  0.621479  ...  0.032810  0.127273  0.277778   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "203  0.361411  0.333629  0.367653  ...  0.154066  0.241558  0.552632   \n",
       "204  0.212348  0.141419  0.291863  ...  0.075606  0.228571  0.365497   \n",
       "205  0.247630  0.175181  0.345488  ...  0.216833  0.062338  0.119883   \n",
       "206  0.235502  0.276914  0.320463  ...  0.111270  0.106494  0.339181   \n",
       "207  0.296582  0.261810  0.320463  ...  0.196862  0.322078  0.108187   \n",
       "\n",
       "          f55       f56       f57       f58       f59       f60  target  \n",
       "0    0.149660  0.417949  0.502841  0.185355  0.245179  0.060046       1  \n",
       "1    0.199546  0.479487  0.389205  0.105263  0.140496  0.087760       1  \n",
       "2    0.394558  0.615385  0.889205  0.368421  0.258953  0.166282       1  \n",
       "3    0.179138  0.176923  0.133523  0.093822  0.107438  0.256351       1  \n",
       "4    0.235828  0.028205  0.196023  0.102975  0.292011  0.203233       1  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "203  0.061224  0.248718  0.176136  0.256293  0.528926  0.348730       0  \n",
       "204  0.129252  0.151282  0.088068  0.066362  0.168044  0.140878       0  \n",
       "205  0.126984  0.217949  0.389205  0.308924  0.209366  0.057737       0  \n",
       "206  0.068027  0.079487  0.088068  0.173913  0.096419  0.096998       0  \n",
       "207  0.074830  0.146154  0.105114  0.075515  0.165289  0.251732       0  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29c6a96-f261-4650-84ec-260b47b2e9e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dx90Sjfwh9cz",
    "outputId": "565c216c-c6e3-48bf-a20b-c64f577ab7f1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82        83\n",
      "           1       0.82      0.73      0.77        73\n",
      "\n",
      "    accuracy                           0.79       156\n",
      "   macro avg       0.80      0.79      0.79       156\n",
      "weighted avg       0.80      0.79      0.79       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model with 25% of data\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.75,random_state=50,stratify=targets)\n",
    "X = np.concatenate((X_train,X_test),axis=0)\n",
    "y = np.concatenate((y_train,y_test),axis=0)\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "# Train the model using the training set\n",
    "clf.fit(X_train, y_train)\n",
    "joblib.dump(clf, f'models/{dataset_name}_svm_model.pkl')\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a63b0ed6-a2dc-467e-b565-5e4b36215888",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.DataFrame(X_test)\n",
    "\n",
    "# Save to CSV\n",
    "X_test_df.to_csv(f'{dataset_name}_results/{dataset_name}_X_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e16f6f-4d86-439e-aab7-50b8de70db0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive patterns = 65,\n",
      "Negative patterns = 91\n"
     ]
    }
   ],
   "source": [
    "# Finding patterns classified as positive/negative\n",
    "positive_indexes,negative_indexes = utility.find_indexes(clf, X_test, threshold=0)\n",
    "print(f\"Positive patterns = {len(positive_indexes)},\\nNegative patterns = {len(negative_indexes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5128478c-c069-4deb-96ae-991e087e4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe with the test data. For comparing Onestep against Twostep.\n",
    "test_df_names = list(df.columns)\n",
    "if 'target' not in test_df_names:\n",
    "    test_df_names.append('target')\n",
    "test_dataset = []\n",
    "for instance, test_class in zip(X_test, y_test.astype('int32')):\n",
    "    test_dataset.append(np.append(instance, test_class))\n",
    "test_dataset_df = pd.DataFrame(np.asarray(test_dataset), columns=test_df_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79d9d9ff-b16c-4660-a043-f46bdeee58bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_df.to_csv(f'{dataset_name}_results/{dataset_name}_X_test_predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eeba5a3-6dc2-42db-8f8d-9859c99e3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter p value\n",
    "p = 0.50\n",
    "\n",
    "#Variables for results\n",
    "times_twostep = []\n",
    "rsum_twostep = []\n",
    "coverage_twostep = []\n",
    "pos_exp_twostep = []\n",
    "neg_exp_twostep = []\n",
    "\n",
    "times_onestep = []\n",
    "rsum_onestep = []\n",
    "coverage_onestep = []\n",
    "pos_exp_onestep = []\n",
    "neg_exp_onestep = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0187334d-f823-4b09-bb5a-83fc45976160",
   "metadata": {},
   "source": [
    "#### Onestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75d1bfce-a363-48cd-afc6-cf0785a5c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Explanations for the patterns classified as negative\n",
    "for idx in  negative_indexes:  \n",
    "    #Onestep\n",
    "    start = time.perf_counter()\n",
    "    exp = docplex_explainer.onestep(\n",
    "            classifier = clf,\n",
    "            dual_coef = clf.dual_coef_,\n",
    "            support_vectors = clf.support_vectors_,\n",
    "            intercept = clf.intercept_,\n",
    "            lower_bound = lower_bound,\n",
    "            upper_bound = upper_bound,\n",
    "            data = (X_test[idx]),\n",
    "            positive = False)\n",
    "    end = time.perf_counter()\n",
    "    times_onestep.append((end - start))\n",
    "    neg_exp_onestep.append(exp)\n",
    "    rsum_onestep.append(mymetrics.range_sum(exp))\n",
    "    coverage_onestep.append(len(mymetrics.calculate_coverage(test_dataset_df, exp)))\n",
    "\n",
    "#Generate Explanations for the patterns classfied as positive\n",
    "for idx in positive_indexes:\n",
    "    #Onestep\n",
    "    start = time.perf_counter()\n",
    "    exp = docplex_explainer.onestep(\n",
    "            classifier = clf,\n",
    "            dual_coef = clf.dual_coef_,\n",
    "            support_vectors = clf.support_vectors_,\n",
    "            intercept = clf.intercept_,\n",
    "            lower_bound = lower_bound,\n",
    "            upper_bound = upper_bound,\n",
    "            data = (X_test[idx]),\n",
    "            positive = True)\n",
    "    end = time.perf_counter()\n",
    "    times_onestep.append((end - start))\n",
    "    pos_exp_onestep.append(exp)\n",
    "    rsum_onestep.append(mymetrics.range_sum(exp))\n",
    "    coverage_onestep.append(len(mymetrics.calculate_coverage(test_dataset_df, exp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9b43e-170c-48b0-970d-3f2dce9a2520",
   "metadata": {},
   "source": [
    "#### Twostep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31f75d41-dbcb-4786-8f57-0308a162910b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generate Explanations for the patterns classified as negative\n",
    "for idx in  negative_indexes:\n",
    "    \n",
    "    #Twostep\n",
    "    start = time.perf_counter()\n",
    "    exp_ = docplex_explainer.twostep(\n",
    "            classifier = clf,\n",
    "            dual_coef = clf.dual_coef_,\n",
    "            support_vectors = clf.support_vectors_,\n",
    "            intercept = clf.intercept_,\n",
    "            lower_bound = lower_bound,\n",
    "            upper_bound = upper_bound,\n",
    "            data = (X_test[idx]),\n",
    "            p = p,\n",
    "            positive = False)\n",
    "    end = time.perf_counter()\n",
    "    times_twostep.append((end - start))\n",
    "    neg_exp_twostep.append(exp_)\n",
    "    rsum_twostep.append(mymetrics.range_sum(exp_))\n",
    "    coverage_twostep.append(len(mymetrics.calculate_coverage(test_dataset_df, exp_)))\n",
    "\n",
    "\n",
    "#Generate Explanations for the patterns classfied as positive\n",
    "for idx in positive_indexes:\n",
    "    \n",
    "    #Twostep\n",
    "    start = time.perf_counter()\n",
    "    exp_ = docplex_explainer.twostep(\n",
    "            classifier = clf,\n",
    "            dual_coef = clf.dual_coef_,\n",
    "            support_vectors = clf.support_vectors_,\n",
    "            intercept = clf.intercept_,\n",
    "            lower_bound = lower_bound,\n",
    "            upper_bound = upper_bound,\n",
    "            data = (X_test[idx]),\n",
    "            p = p,\n",
    "            positive = True)\n",
    "    end = time.perf_counter()\n",
    "    times_twostep.append((end - start))\n",
    "    pos_exp_twostep.append(exp_)\n",
    "    rsum_twostep.append(mymetrics.range_sum(exp_))\n",
    "    coverage_twostep.append(len(mymetrics.calculate_coverage(test_dataset_df, exp_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597f13a-b41a-478a-a62c-13f24752a20f",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfc23c7b-6ef8-4b12-8934-e51489be91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature expansion sizes for Twostep\n",
    "frequency_twostep_neg = utility.detail_exp(\n",
    "    explanations=neg_exp_twostep, \n",
    "    patterns=X_test[negative_indexes],\n",
    "    number_of_features=len(X_test[0]), \n",
    "    show_explanation=False, \n",
    "    show_frequency=False, \n",
    "    low_val=lower_bound, \n",
    "    upp_val=upper_bound\n",
    ")\n",
    "\n",
    "frequency_twostep_pos = utility.detail_exp(\n",
    "    explanations=pos_exp_twostep, \n",
    "    patterns=X_test[positive_indexes],\n",
    "    number_of_features=len(X_test[0]), \n",
    "    show_explanation=False, \n",
    "    show_frequency=False, \n",
    "    low_val=lower_bound, \n",
    "    upp_val=upper_bound\n",
    ")\n",
    "\n",
    "neg_sizes_twostep = np.count_nonzero(frequency_twostep_neg.to_numpy() == 1, axis=1)\n",
    "pos_sizes_twostep = np.count_nonzero(frequency_twostep_pos.to_numpy() == 1, axis=1)\n",
    "feature_sizes_twostep = np.concatenate([neg_sizes_twostep, pos_sizes_twostep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca404cc-4e44-4cba-975a-e1b0d94172d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature expansion sizes for Onestep\n",
    "frequency_onestep_neg = utility.detail_exp(\n",
    "    explanations=neg_exp_onestep, \n",
    "    patterns=X_test[negative_indexes],\n",
    "    number_of_features=len(X_test[0]), \n",
    "    show_explanation=False, \n",
    "    show_frequency=False, \n",
    "    low_val=lower_bound, \n",
    "    upp_val=upper_bound\n",
    ")\n",
    "\n",
    "frequency_onestep_pos = utility.detail_exp(\n",
    "    explanations=pos_exp_onestep, \n",
    "    patterns=X_test[positive_indexes],\n",
    "    number_of_features=len(X_test[0]), \n",
    "    show_explanation=False, \n",
    "    show_frequency=False, \n",
    "    low_val=lower_bound, \n",
    "    upp_val=upper_bound\n",
    ")\n",
    "\n",
    "# Use np.count_nonzero\n",
    "neg_sizes_onestep = np.count_nonzero(frequency_onestep_neg.to_numpy() == 1, axis=1)\n",
    "pos_sizes_onestep = np.count_nonzero(frequency_onestep_pos.to_numpy() == 1, axis=1)\n",
    "\n",
    "# Concatenate directly\n",
    "feature_sizes_onestep = np.concatenate([neg_sizes_onestep, pos_sizes_onestep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d68788c-b895-4bde-9ff4-ca09c26de101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: found possible division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mateus\\AppData\\Local\\Temp\\ipykernel_428\\760104910.py:9: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return np.where(old != 0, ((new - old) / old) * 100, np.nan)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>ONESTEP_MEAN</th>\n",
       "      <th>ONESTEP_STD</th>\n",
       "      <th>TWOSTEP_MEAN</th>\n",
       "      <th>TWOSTEP_STD</th>\n",
       "      <th>MEAN_DIFF_%</th>\n",
       "      <th>STD_DIFF_%</th>\n",
       "      <th>POINTWISE_MEAN_%</th>\n",
       "      <th>POINTWISE_STD_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Time</td>\n",
       "      <td>0.183423</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.300317</td>\n",
       "      <td>0.026482</td>\n",
       "      <td>63.728761</td>\n",
       "      <td>164.582239</td>\n",
       "      <td>63.782587</td>\n",
       "      <td>12.107260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Size</td>\n",
       "      <td>51.647436</td>\n",
       "      <td>3.800817</td>\n",
       "      <td>51.647436</td>\n",
       "      <td>3.800817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ranges_Sum</td>\n",
       "      <td>31.849594</td>\n",
       "      <td>2.596340</td>\n",
       "      <td>31.854303</td>\n",
       "      <td>2.597341</td>\n",
       "      <td>0.014787</td>\n",
       "      <td>0.038559</td>\n",
       "      <td>0.014639</td>\n",
       "      <td>0.015894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coverage</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Metric  ONESTEP_MEAN  ONESTEP_STD  TWOSTEP_MEAN  TWOSTEP_STD  \\\n",
       "0        Time      0.183423     0.010009      0.300317     0.026482   \n",
       "1        Size     51.647436     3.800817     51.647436     3.800817   \n",
       "2  Ranges_Sum     31.849594     2.596340     31.854303     2.597341   \n",
       "3    Coverage      1.000000     0.000000      1.000000     0.000000   \n",
       "\n",
       "   MEAN_DIFF_%  STD_DIFF_%  POINTWISE_MEAN_%  POINTWISE_STD_%  \n",
       "0    63.728761  164.582239         63.782587        12.107260  \n",
       "1     0.000000         0.0          0.000000         0.000000  \n",
       "2     0.014787    0.038559          0.014639         0.015894  \n",
       "3     0.000000         nan          0.000000         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute means and standard deviations\n",
    "def compute_mean_std(arr):\n",
    "    return np.mean(arr), np.std(arr)\n",
    "\n",
    "# Compute relative percentage differences\n",
    "def relative_percentage_diff(new, old):\n",
    "    if np.any(old == 0):\n",
    "        print(f'Warning: found possible division by zero')\n",
    "        return np.where(old != 0, ((new - old) / old) * 100, np.nan)\n",
    "    return ((new - old) / old) * 100\n",
    "\n",
    "# Ensure all lists are NumPy arrays\n",
    "times_onestep = np.array(times_onestep)\n",
    "times_twostep = np.array(times_twostep)\n",
    "feature_sizes_onestep = np.array(feature_sizes_onestep)\n",
    "feature_sizes_twostep = np.array(feature_sizes_twostep)\n",
    "rsum_onestep = np.array(rsum_onestep)\n",
    "rsum_twostep = np.array(rsum_twostep)\n",
    "coverage_onestep = np.array(coverage_onestep)\n",
    "coverage_twostep = np.array(coverage_twostep)\n",
    "\n",
    "# Compute means and standard deviations\n",
    "(time_mean_onestep, time_std_onestep) = compute_mean_std(times_onestep)\n",
    "(time_mean_twostep, time_std_twostep) = compute_mean_std(times_twostep)\n",
    "\n",
    "(sizes_mean_onestep, sizes_std_onestep) = compute_mean_std(feature_sizes_onestep)\n",
    "(sizes_mean_twostep, sizes_std_twostep) = compute_mean_std(feature_sizes_twostep)\n",
    "\n",
    "(rsum_mean_onestep, rsum_std_onestep) = compute_mean_std(rsum_onestep)\n",
    "(rsum_mean_twostep, rsum_std_twostep) = compute_mean_std(rsum_twostep)\n",
    "\n",
    "(coverage_mean_onestep, coverage_std_onestep) = compute_mean_std(coverage_onestep)\n",
    "(coverage_mean_twostep, coverage_std_twostep) = compute_mean_std(coverage_twostep)\n",
    "\n",
    "# Compute relative percentage differences (Mean & Std)\n",
    "time_mean_diff = relative_percentage_diff(time_mean_twostep, time_mean_onestep)\n",
    "sizes_mean_diff = relative_percentage_diff(sizes_mean_twostep, sizes_mean_onestep)\n",
    "rsum_mean_diff = relative_percentage_diff(rsum_mean_twostep, rsum_mean_onestep)\n",
    "coverage_mean_diff = relative_percentage_diff(coverage_mean_twostep, coverage_mean_onestep)\n",
    "\n",
    "time_std_diff = relative_percentage_diff(time_std_twostep, time_std_onestep)\n",
    "sizes_std_diff = relative_percentage_diff(sizes_std_twostep, sizes_std_onestep)\n",
    "rsum_std_diff = relative_percentage_diff(rsum_std_twostep, rsum_std_onestep)\n",
    "coverage_std_diff = relative_percentage_diff(coverage_std_twostep, coverage_std_onestep)\n",
    "\n",
    "# Compute pointwise relative differences\n",
    "time_relative_pointwise = relative_percentage_diff(times_twostep, times_onestep)\n",
    "sizes_relative_pointwise = relative_percentage_diff(feature_sizes_twostep, feature_sizes_onestep)\n",
    "rsum_relative_pointwise = relative_percentage_diff(rsum_twostep, rsum_onestep)\n",
    "coverage_relative_pointwise = relative_percentage_diff(coverage_twostep, coverage_onestep)\n",
    "\n",
    "# Compute pointwise means\n",
    "time_relative_mean = np.mean(time_relative_pointwise) \n",
    "sizes_relative_mean = np.mean(sizes_relative_pointwise)\n",
    "rsum_relative_mean = np.mean(rsum_relative_pointwise)\n",
    "coverage_relative_mean = np.mean(coverage_relative_pointwise)\n",
    "\n",
    "# Compute pointwise standard deviations\n",
    "time_relative_std = np.std(time_relative_pointwise) \n",
    "sizes_relative_std = np.std(sizes_relative_pointwise)\n",
    "rsum_relative_std = np.std(rsum_relative_pointwise)\n",
    "coverage_relative_std = np.std(coverage_relative_pointwise)\n",
    "\n",
    "# Organize Data\n",
    "all_metrics_data = {\n",
    "    'Metric': ['Time', 'Size', 'Ranges_Sum', 'Coverage'],\n",
    "    'ONESTEP_MEAN': [time_mean_onestep, sizes_mean_onestep, rsum_mean_onestep, coverage_mean_onestep],\n",
    "    'ONESTEP_STD': [time_std_onestep, sizes_std_onestep, rsum_std_onestep, coverage_std_onestep],\n",
    "    'TWOSTEP_MEAN': [time_mean_twostep, sizes_mean_twostep, rsum_mean_twostep, coverage_mean_twostep],\n",
    "    'TWOSTEP_STD': [time_std_twostep, sizes_std_twostep, rsum_std_twostep, coverage_std_twostep],\n",
    "    'MEAN_DIFF_%': [time_mean_diff, sizes_mean_diff, rsum_mean_diff, coverage_mean_diff],\n",
    "    'STD_DIFF_%': [time_std_diff, sizes_std_diff, rsum_std_diff, coverage_std_diff],\n",
    "    'POINTWISE_MEAN_%': [time_relative_mean, sizes_relative_mean, rsum_relative_mean, coverage_relative_mean],\n",
    "    'POINTWISE_STD_%': [time_relative_std, sizes_relative_std, rsum_relative_std, coverage_relative_std]\n",
    "}\n",
    "# Display and save\n",
    "all_metrics_df = pd.DataFrame(all_metrics_data)\n",
    "display(all_metrics_df)\n",
    "all_metrics_df.to_csv(f'{dataset_name}_results/results_{p}.csv', index=False)\n",
    "\n",
    "#Save Raw Metric Data\n",
    "raw_df = pd.DataFrame({\n",
    "    \"times_onestep\": times_onestep, \n",
    "    \"times_twostep\": times_twostep,\n",
    "    \"feature_sizes_onestep\": feature_sizes_onestep, \n",
    "    \"feature_sizes_twostep\": feature_sizes_twostep,\n",
    "    \"rsum_onestep\": rsum_onestep, \n",
    "    \"rsum_twostep\": rsum_twostep,\n",
    "    \"coverage_onestep\": coverage_onestep, \n",
    "    \"coverage_twostep\": coverage_twostep,\n",
    "    \"time_relative_%\": time_relative_pointwise,\n",
    "    \"sizes_relative_%\": sizes_relative_pointwise,\n",
    "    \"rsum_relative_%\": rsum_relative_pointwise,\n",
    "    \"coverage_relative_%\": coverage_relative_pointwise\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "raw_df.to_csv(f\"{dataset_name}_results/raw_metric_data_{p}.csv\", index=False)\n",
    "\n",
    "np.savez(f'{dataset_name}_results/neg_explanations_{p}.npz', \n",
    "         neg_exp_onestep=neg_exp_onestep, \n",
    "         neg_exp_twostep=neg_exp_twostep)\n",
    "\n",
    "# Save positive explanations\n",
    "np.savez(f'{dataset_name}_results/pos_explanations_{p}.npz', \n",
    "         pos_exp_onestep=pos_exp_onestep, \n",
    "         pos_exp_twostep=pos_exp_twostep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addac62e-d1b2-447b-b2da-0875b0647e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
